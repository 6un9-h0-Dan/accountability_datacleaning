---
title: "Data Diary"
subtitle: "New Jersey Contributions"
author: "Kiernan Nicholls"
date: "`r format(Sys.time())`"
output:
  html_document: 
    df_print: tibble
    fig_caption: yes
    highlight: tango
    keep_md: yes
    max.print: 32
    toc: yes
    toc_float: no
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(
  echo = TRUE,
  warning = FALSE
)
options(width = 99)
```

## Objectives

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called ZIP5
1. Create a YEAR field from the transaction date
1. For campaign donation data, make sure there is both a donor AND recipient

## Packages

```{r libs, message=FALSE, warning=FALSE, error=FALSE}
# install.packages("pacman")
pacman::p_load(
  tidyverse,
  RSelenium,
  lubridate,
  magrittr,
  janitor,
  zipcode, 
  here
)
```

## Data

Data comes courtesy of the New Jersey Election Law Enforcement Commission (ELEC)
[website](https://www.elec.state.nj.us/ELECReport/). The data can be downloaded from their 
["Quick Data Downloads"](https://www.elec.state.nj.us/publicinformation/quickdownload.htm) page in
four separate files:

* `All_GUB_Text.zip`
* `All_LEG_Text.zip`
* `All_CW_Text.zip`
* `All_PAC_Text.zip`

Each ZIP file contains a number of individual TXT files separated by year.

ELEC makes the following disclaimer at the bottom of the download page:

> The data contained in the ELEC database includes information as reported by candidates and
committees. Although ELEC has taken all reasonable precautions to prevent data entry errors, the
possibility that some exist cannot be entirely eliminated. Contributor and Expenditure types are
coded by ELEC staff members and are subjective according to the information provided by the filer.
Additionally, this information is subject to change as amendments are filed by candidates and
committees. For the most up-to-date information, please go to the “Search for Contributions” pages
to search for the most recent contributor information.

## Read

Each of the ZIP files can be read using the following process:

1. Download from ELEC with `utils::download.file()`
1. Unzip the file into a local directory with `utils::unzip()`
1. Create a vector of new file names with `base::list.files()`
1. Read all the files into a list by mapping `readr::read_delim()` to each file with `purrr:map()`
    * All files have `.txt` extension, but some are really `.tsv` and others `.csv`. Use the
    appropriate `readr::read_*` function for each deliminator type
    * Read all columns as character except for `CONT_DATE` and `CONT_AMT`
1. Combined the rows from each list element into a single table with `dplyr::bind_rows()`
1. Repeat for other ZIP files

```{r read_gub}
# download the file
download.file(
  url = "https://www.elec.state.nj.us/download/Data/Gubernatorial/All_GUB_Text.zip",
  destfile = here("nj_contribs", "data", "All_GUB_Text.zip")
)

# unzip into a folder
unzip(
  zipfile = here("nj_contribs", "data", "All_GUB_Text.zip"),
  overwrite = TRUE,
  exdir = here("nj_contribs", "data", "All_GUB")
)

# list the new files
nj_gub_files <- list.files(
  path = here("nj_contribs", "data", "All_GUB"),
  full.names = TRUE
)

# read files with tab delims
nj_gub_tsv <- map(
  nj_gub_files[-c(8, 16, 24)],
  read_tsv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_date("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

# read files with comma delims
nj_gub_csv <- map(
  nj_gub_files[c(8, 16, 24)],
  read_csv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_date("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

# combined all year tables
nj_gub <- bind_rows(nj_gub_tsv, nj_gub_csv)

# remove intermediate data
rm(nj_gub_files, nj_gub_tsv, nj_gub_csv)
```

```{r read_leg}
download.file(
  url = "https://www.elec.state.nj.us/download/Data/Legislative/All_LEG_Text.zip",
  destfile = here("nj_contribs", "data", "All_LEG_Text.zip")
)

unzip(
  zipfile = here("nj_contribs", "data", "All_LEG_Text.zip"),
  overwrite = TRUE,
  exdir = here("nj_contribs", "data", "All_LEG")
)

nj_leg_files <- list.files(
  path = here("nj_contribs", "data", "All_LEG"),
  full.names = TRUE
)

nj_leg_tsv <- map(
  nj_leg_files[-c(16:18, 31:33)],
  read_tsv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_date("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

nj_leg_csv <- map(
  nj_leg_files[c(16:18, 31:33)],
  read_csv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_date("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

nj_leg <- bind_rows(nj_leg_tsv, nj_leg_csv)

rm(nj_leg_files, nj_leg_tsv, nj_leg_csv)
```

```{r read_local}
download.file(
  url = "https://www.elec.state.nj.us/download/Data/Countywide/All_CW_Text.zip",
  destfile = here("nj_contribs", "data", "All_CW_Text.zip")
)

unzip(
  zipfile = here("nj_contribs", "data", "All_CW_Text.zip"),
  overwrite = TRUE,
  exdir = here("nj_contribs", "data", "All_CW")
)

nj_cw_files <- list.files(
  path = here("nj_contribs", "data", "All_CW"),
  full.names = TRUE
)

nj_cw_tsv <- map(
  nj_cw_files[-c(5:9, 14:18)],
  read_tsv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_date("%m/%d/%Y"),
    CONT_AMT = col_number()
  )
)

nj_cw_csv <- map(
  nj_cw_files[c(5:9, 14:18)],
  read_csv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_date("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

nj_cw <- bind_rows(nj_cw_tsv, nj_cw_csv)

rm(nj_cw_files, nj_cw_tsv, nj_cw_csv)
```

```{r read_pac}
download.file(
  url = "https://www.elec.state.nj.us/download/Data/PAC/All_PAC_Text.zip",
  destfile = here("nj_contribs", "data", "All_PAC_Text.zip")
)

unzip(
  zipfile = here("nj_contribs", "data", "All_PAC_Text.zip"),
  overwrite = TRUE,
  exdir = here("nj_contribs", "data", "All_PAC")
)

nj_pac_files <- list.files(
  path = here("nj_contribs", "data", "All_PAC"),
  full.names = TRUE
)

nj_pac_tsv <- map(
  nj_pac_files[-c(19, 21, 22)],
  read_tsv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_date("%m/%d/%Y"),
    CONT_AMT = col_number()
  )
)

nj_pac_csv <- map(
  nj_pac_files[c(19, 21, 22)],
  read_csv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_date("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

nj_pac <- bind_rows(nj_pac_tsv, nj_pac_csv)

rm(nj_pac_files, nj_pac_tsv, nj_pac_csv)
```

Since each file has the same structure, we can bind them all into a single data frame.

```{r bind_all}
nj <-
  bind_rows(nj_gub, nj_leg, nj_cw, nj_pac, .id = "source") %>%
  clean_names() %>%
  arrange(desc(election_year)) %>%
  mutate(
    source = source %>%
      recode(
        "1" = "gub",
        "2" = "leg",
        "3" = "cw",
        "4" = "pac"
      )
  )

rm(nj_gub, nj_leg, nj_cw, nj_pac)
```

## Explore

Below is the structure of the data arranged randomly by row. There are `r nrow(nj)` rows of 
`r length(nj)` variables.

```{r glimpse_all}
glimpse(sample_frac(nj))
```

The hard files contain data on elections from `r min(nj$election_year)` to `r
max(nj$election_year)`. When you filter out those contributions made before 2008, about
$\frac{2}{3}$ of the data is remove.

```{r filter_date}
nj <- nj %>% filter(cont_date > "2008-01-01")
nrow(nj)
min(nj$cont_date)
max(nj$cont_date)
```

There are `r nrow(nj)-nrow(distinct(nj))` rows with duplicates values in every variable. Over 1% of
rows are complete duplicates.

```{r n_distinct}
nrow(distinct(nj)) - nrow(nj)
```

The variables vary in their degree of distinctedness.

```{r count_distinct}
nj %>% 
  map(n_distinct) %>% 
  unlist() %>% 
  enframe(name = "variable", value = "n_distinct") %>% 
  mutate(prop_distinct = round(n_distinct / nrow(nj), 4)) %>%
  print(n = length(nj))
```

There are nearly 1,300 records with values across every variable duplicated at least once more.

```{r get_dupes}
# create dupes df
nj_dupes <- nj %>% 
  get_dupes() %>%
  distinct() %>% 
  mutate(dupe_flag = TRUE)

# show dupes
nj_dupes %>% 
  mutate(rec = coalesce(rec_lname, rec_non_ind_name)) %>% 
  select(
    cont_lname,
    cont_amt,
    cont_date,
    rec,
    dupe_count
  ) %>% 
  print()
```

Flag these duplicate rows by joining the duplicate table with the original data.

```{r}
nj <- left_join(nj, nj_dupes)
```

Since there is no entirely unique variable to track contributions, we will create one.

```{r rownames_to_column, collapse=TRUE}
nj <- nj %>% rownames_to_column(var = "id")
n_distinct(nj$id) == nrow(nj)
```


```{r count_na}
nj %>% map(function(v) sum(is.na(v))) %>% 
  unlist() %>% 
  enframe(name = "variable", value = "n_na") %>% 
  mutate(prop_na = n_na / nrow(nj)) %>% 
  print(n = length(nj))
```

## Clean

### Year

```{r mutate_year}
# extract year variable
nj <- nj %>% mutate(year = year(nj$cont_date))

# print all years
sort(unique(nj$year))

# view futures contribs
nj %>% 
  filter(cont_date > today()) %>% 
  arrange(cont_date) %>% 
  mutate(cont = coalesce(cont_lname, cont_non_ind_name)) %>% 
  mutate(rec = coalesce(rec_lname, rec_non_ind_name)) %>% 
  select(cont_date, cont, cont_amt, rec, source)

# flag future contribs
nj <- nj %>% 
  filter(cont_date > today()) %>% 
  mutate(date_flag = TRUE) %>% 
  right_join(nj)
```

### Zips

```{r mutate_zip5}
data("zipcode")
nj <- nj %>% mutate(zip5 = clean.zipcodes(cont_zip))
```

```{r clean_zip5}
nj %>% 
  filter(nchar(zip5) != 5) %>% 
  select(cont_city, cont_state, cont_zip, zip5) %>% 
  print(n = nrow(.))
```

### States

```{r clean_state}
nj %>% 
  filter(cont_state %in% setdiff(cont_state, c(state.abb, "DC"))) %>% 
  select(cont_city, cont_state, cont_zip) %>% 
  filter(!is.na(cont_state)) %>% 
  left_join(
    y = zipcode %>% select(zip, city, state), 
    by = c("cont_zip" = "zip")
  )
```

