---
title: "Data Diary"
subtitle: "New Jersey Contributions"
author: "Kiernan Nicholls"
date: "`r format(Sys.time())`"
output:
  html_document: 
    df_print: tibble
    fig_caption: yes
    highlight: tango
    keep_md: yes
    max.print: 32
    toc: yes
    toc_float: no
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(
  echo = TRUE,
  warning = FALSE
)
options(width = 99)
```

## Objectives

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called ZIP5
1. Create a YEAR field from the transaction date
1. For campaign donation data, make sure there is both a donor AND recipient

## Packages

```{r libs, message=FALSE, warning=FALSE, error=FALSE}
# install.packages("pacman")
pacman::p_load(
  tidyverse,
  RSelenium,
  lubridate,
  magrittr,
  janitor,
  zipcode, 
  here
)
```

## Data

Data comes courtesy of the New Jersey Election Law Enforcement Commission (ELEC)
[website](https://www.elec.state.nj.us/ELECReport/). The data can be downloaded from their 
["Quick Data Downloads"](https://www.elec.state.nj.us/publicinformation/quickdownload.htm) page in
four separate files:

* `All_GUB_Text.zip`
* `All_LEG_Text.zip`
* `All_CW_Text.zip`
* `All_PAC_Text.zip`

Each ZIP file contains a number of individual TXT files separated by year.

## Read

Each of the ZIP files can be read using the following process:

1. Download from ELEC with `utils::download.file()`
1. Unzip the file into a local directory with `utils::unzip()`
1. Create a vector of new file names with `base::list.files()`
1. Read all the files into a list by mapping `readr::read_delim()` to each file with `purrr:map()`
    * All files have `.txt` extension, but some are really `.tsv` and others `.csv`. Use the
    appropriate `readr::read_*` function for each deliminator type
    * Read all columns as character except for `CONT_DATE` and `CONT_AMT`
1. Combined the rows from each list element into a single table with `dplyr::bind_rows()`
1. Repeat for other ZIP files

```{r read_gub}
# download the file
download.file(
  url = "https://www.elec.state.nj.us/download/Data/Gubernatorial/All_GUB_Text.zip",
  destfile = here("nj_contribs", "data", "All_GUB_Text.zip")
)

# unzip into a folder
unzip(
  zipfile = here("nj_contribs", "data", "All_GUB_Text.zip"),
  overwrite = TRUE,
  exdir = here("nj_contribs", "data", "All_GUB")
)

# list the new files
nj_gub_files <- list.files(
  path = here("nj_contribs", "data", "All_GUB"),
  full.names = TRUE
)

# read files with tab delims
nj_gub_tsv <- map(
  nj_gub_files[-c(8, 16, 24)],
  read_tsv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_datetime("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

# read files with comma delims
nj_gub_csv <- map(
  nj_gub_files[c(8, 16, 24)],
  read_csv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_datetime("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

# combined all year tables
nj_gub <- bind_rows(nj_gub_tsv, nj_gub_csv)

# remove intermediate data
rm(nj_gub_files, nj_gub_tsv, nj_gub_csv)
```

```{r read_leg}
download.file(
  url = "https://www.elec.state.nj.us/download/Data/Legislative/All_LEG_Text.zip",
  destfile = here("nj_contribs", "data", "All_LEG_Text.zip")
)

unzip(
  zipfile = here("nj_contribs", "data", "All_LEG_Text.zip"),
  overwrite = TRUE,
  exdir = here("nj_contribs", "data", "All_LEG")
)

nj_leg_files <- list.files(
  path = here("nj_contribs", "data", "All_LEG"),
  full.names = TRUE
)

nj_leg_tsv <- map(
  nj_leg_files[-c(16:18, 31:33)],
  read_tsv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_datetime("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

nj_leg_csv <- map(
  nj_leg_files[c(16:18, 31:33)],
  read_csv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_datetime("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

nj_leg <- bind_rows(nj_leg_tsv, nj_leg_csv)

rm(nj_leg_files, nj_leg_tsv, nj_leg_csv)
```

```{r read_local}
download.file(
  url = "https://www.elec.state.nj.us/download/Data/Countywide/All_CW_Text.zip",
  destfile = here("nj_contribs", "data", "All_CW_Text.zip")
)

unzip(
  zipfile = here("nj_contribs", "data", "All_CW_Text.zip"),
  overwrite = TRUE,
  exdir = here("nj_contribs", "data", "All_CW")
)

nj_cw_files <- list.files(
  path = here("nj_contribs", "data", "All_CW"),
  full.names = TRUE
)

nj_cw_tsv <- map(
  nj_cw_files[-c(5:9, 14:18)],
  read_tsv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_datetime("%m/%d/%Y"),
    CONT_AMT = col_number()
  )
)

nj_cw_csv <- map(
  nj_cw_files[c(5:9, 14:18)],
  read_csv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_datetime("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

nj_cw <- bind_rows(nj_cw_tsv, nj_cw_csv)

rm(nj_cw_files, nj_cw_tsv, nj_cw_csv)
```

```{r read_pac}
download.file(
  url = "https://www.elec.state.nj.us/download/Data/PAC/All_PAC_Text.zip",
  destfile = here("nj_contribs", "data", "All_PAC_Text.zip")
)

unzip(
  zipfile = here("nj_contribs", "data", "All_PAC_Text.zip"),
  overwrite = TRUE,
  exdir = here("nj_contribs", "data", "All_PAC")
)

nj_pac_files <- list.files(
  path = here("nj_contribs", "data", "All_PAC"),
  full.names = TRUE
)

nj_pac_tsv <- map(
  nj_pac_files[-c(19, 21, 22)],
  read_tsv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_datetime("%m/%d/%Y"),
    CONT_AMT = col_number()
  )
)

nj_pac_csv <- map(
  nj_pac_files[c(19, 21, 22)],
  read_csv,
  col_types = cols(
    .default = col_character(),
    CONT_DATE = col_datetime("%m/%d/%Y"),
    CONT_AMT = col_double()
  )
)

nj_pac <- bind_rows(nj_pac_tsv, nj_pac_csv)

rm(nj_pac_files, nj_pac_tsv, nj_pac_csv)
```

Since each file has the same structure, we can bind them all into a single data frame.

```{r bind_all}
names(nj_gub)

nj <-
  bind_rows(nj_gub, nj_leg, nj_cw, nj_pac, .id = "source") %>%
  clean_names() %>%
  arrange(desc(election_year)) %>%
  mutate(
    source = source %>%
      recode(
        "1" = "gub",
        "2" = "leg",
        "3" = "cw",
        "4" = "pac"
      )
  )

rm(nj_gub, nj_leg, nj_cw, nj_pac)
```

## Explore

Below is the structure of the data arranged randomly by row. There are `r nrow(nj)` rows of 
`r length(nj)` variables.

```{r glimpse_all}
glimpse(sample_frac(nj))
```

The hard copy files span from `r min(nj$election_year)` to `r max(nj$election_year)`. When you
filter out those records from before 2008, you are left with much less data.

```{r dims_new}
nj2 <- nj %>% filter(cont_date > "2008-01-01")
nrow(nj2)
min(nj2$cont_date)
max(nj2$cont_date)
```

There are a little under 2,000 rows with duplicates values in every variable. Over 1% of rows
are complete duplicates.

```{r}
nj2 %>% 
  distinct() %>% 
  nrow() %>% 
  subtract(nrow(nj2))
```

## Write

```{r}
write_csv(
  x = nj2,
  path = here("nj_contribs", "data", "nj_2008-2013"),
  na = "",
  col_names = TRUE,
  quote_escape = "backslash"
)
```

