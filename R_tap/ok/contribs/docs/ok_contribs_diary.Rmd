---
title: "Oklahoma Contributions"
author: "Kiernan Nicholls"
date: "`r date()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 3
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
if (!interactive()) {
  options(width = 120)
  set.seed(5)
}
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
doc_dir <- fs::dir_create(here::here("ok", "contribs", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give
journalists, policy professionals, activists, and the public at large a simple
way to search across huge volumes of public data about people and organizations.

Our goal is to standardize public data on a few key fields by thinking of each
dataset row as a transaction. For each transaction there should be (at least) 3
variables:

1. All **parties** to a transaction.
2. The **date** of the transaction.
3. The **amount** of money involved.

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for entirely duplicated records.
1. Check ranges of continuous variables.
1. Is there anything blank or missing?
1. Check for consistency issues.
1. Create a five-digit ZIP Code called `zip`.
1. Create a `year` field from the transaction date.
1. Make sure there is data on both parties to a transaction.

## Packages

The following packages are needed to collect, manipulate, visualize, analyze,
and communicate these results. The `pacman` package will facilitate their
installation and attachment.

```{r load_packages, message=FALSE, warning=FALSE, error=FALSE}
if (!require("pacman")) {
  install.packages("pacman")
}
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  textreadr, # read doc files
  gluedown, # printing markdown
  janitor, # clean data frames
  campfin, # custom irw tools
  aws.s3, # aws cloud storage
  refinr, # cluster & merge
  readxl, # read excel files
  scales, # format strings
  knitr, # knit documents
  rvest, # scrape html
  glue, # code strings
  here, # project paths
  httr, # http requests
  fs # local storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a
sub-directory of the more general, language-agnostic
[`irworkshop/accountability_datacleaning`][tap] GitHub repository.

The `R_campfin` project uses the [RStudio projects][rproj] feature and should be
run as such. The project also uses the dynamic `here::here()` tool for file
paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::i_am("ok/contribs/docs/ok_contribs_diary.Rmd")
```

[tap]: https://github.com/irworkshop/accountability_datacleaning
[rproj]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects

## Data

Oklahoma contributions can be downloaded as a ZIP archive from the
[Oklahoma Ethics Commission's Campaign Reporting System][oec]. This website
providers uses with the ability to get all campaign finance data.

> #### Welcome to the Oklahoma Ethics Commission's Public Disclosure System. 
>
> In accordance to the Open Records Act, Section 24A.1 et seq. of Title 51 of
the Oklahoma Statutes you will be able to search and retrieve reports and data
filed by registered candidate and non-candidate committees in the state of
Oklahoma.
> 
> This system is designed to provide accurate and timely information to the
public.
>
> You can search for data by the following means:
>
> * Statistical Information
> * Advanced Contributor Searches
> * Advanced Expenditure Search
> * Search Paper Reports (all or specific)
> * Download Raw Data (available after secure login)
> * Candidate Information
> * Non-Candidate Committee Information
> * Position, District, Office Number
> * Campaign Fund Balances

The [Helpful Hints][hh] page provides information on the type of data available
for bulk download.

> #### Who can use the public disclosure system?
> Everyone has access to the public disclosure system, the only secured access
point is the downloadable raw data option. This option provides an entire
database dump in comma separated value (`.csv`) or tab delimited (`.txt`)
formats. This secure area is intended for use by the media and import into an
existing database.

> #### How quickly are filed reports available online?
> As soon as a report is submitted online by a committee it is available online
through the public disclosure.

The OEC also provides two files providing table descriptions and relationships
between the available tables.

```{r about_relate}
relate_xls <- here("ok", "contribs", "data", "relations_db.xls")
if (!file_exists(relate_xls)) {
  relate_get <- GET(
    url = "https://www.ok.gov/ethics/public/dfile.php",
    query = list(action = "relation"),
    write_disk(relate_xls),
    progress("down")
  )
}
relate <- read_excel(relate_xls)
```

```{r about_desc}
desc_doc <- here("ok", "contribs", "data", "descriptions.doc")
if (!file_exists(desc_doc)) {
  desc_get <- GET(
    url = "https://www.ok.gov/ethics/public/dfile.php",
    query = list(action = "relation"),
    write_disk(desc_doc),
    progress("down")
  )
}
desc <- read_doc(desc_doc)
```

[oec]: https://pay.apps.ok.gov/ethics/crs/index.php
[hh]: https://apps.ok.gov/ethics/public/helpful_hints.php

## Download

The [Raw Data Download][rdd] page provides links to download the bulk data as a
single archive containing comma-separated text files. This `ethicscsvfile.zip`
archive file can be downloaded locally if it does not exist or is more than a
day old.

```{r raw_dir}
raw_head <- HEAD(
  url = "https://www.ok.gov/ethics/public/dfile.php",
  query = list(action = "csv"),
)
raw_disp <- headers(raw_head)[["content-disposition"]]
raw_dir <- dir_create(here("ok", "contribs", "data", "raw"))
raw_zip <- path(raw_dir, str_extract(raw_disp, "(?<=\\=)(.*)$"))
```

```{r file_age}
file_age <- function(...) {
  finfo <- file.info(...)
  lubridate::as.period(Sys.time() - finfo$mtime)
}
```

```{r raw_download}
if (!file_exists(raw_zip) || hour(file_age(raw_zip)) > 24) {
  raw_get <- GET(
    url = "https://www.ok.gov/ethics/public/dfile.php",
    query = list(action = "csv"),
    write_disk(raw_zip, overwrite = TRUE),
    progress("down")
  )
}
```

[rdd]: https://apps.ok.gov/ethics/public/login.php

### Unzip

The `ethicstabfile.zip` file is an archive containing 48 text files.

```{r zip_list, echo=FALSE}
as_tibble(unzip(raw_zip, list = TRUE))
```

```{r zip_unzip}
raw_csv <- unzip(raw_zip, exdir = raw_dir)
```

## Read

The data of interest is spread across a number of different files than can be
joined along their respective `*_id` variables. The `transaction.csv` contains
the list of contributions and expenses, and data on those transactions is spread
across other tables.

The relationship between these files is described in the `relations_db.xls`
Excel file. Descriptions for each of these files is provided int the
`descriptions.doc` Word file.

In general, there are three _types_ of files that need to be read and joined together

1. All transactions
    * `transaction.csv`
1. Contributor information
    * `contributor.csv`
    * `cont_type.csv`
    * `individual_cont.csv`
    * `business_cont.csv`
    * `committee_cont.csv`
    * `vendor_cont.csv`
1. Recipient information
    * `so1.csv`
    * `so2.csv`
    * `party.csv`
    * `district.csv`
    * `office.csv`
    * `affiliation.csv`
    * `report.csv`
    * `lump_fund.csv`
    * `surplus.csv`
    * `refund.csv`

They will each be read as data frames using `read_csv()`. All files contain an
erroneous trailing column in the header resulting in an empty column that will
be removed. All variable names will be made "clean" (lowercase and snake_case)
using `make_clean_names()`. We can create a function that will let us easily
apply these steps to each file.

```{r read_ok}
read_okc <- function(name, dir = here("ok", "contribs", "data", "raw"), ...) {
  # find path to file name
  ok_path <- file.path(dir, name)
  # readr first line of file
  ok_head <- readLines(ok_path, n = 1)
  # split into vector of col names
  ok_names <- strsplit(ok_head, split = ",")[[1]]
  # make non-empty values lowercase
  ok_names <- tolower(ok_names[nzchar(ok_names)])
  # read file with new col names
  readr::read_csv(ok_path, skip = 1, col_names = ok_names, ...)
}
```

### Transactions

> Holds all the contribution and expenditure transactions. Has the transaction
date, amount, the contributor id and report number (report_num) that it ties
back to in the report table.

```{r read_transaction}
transaction <- read_okc(
  name = "transaction.csv",
  col_types = cols(
    trans_index = col_integer(),
    transaction_date = col_date("%d-%b-%y"),
    contributor_id = col_integer(),
    trans_amount = col_double(),
    rep_num = col_integer()
  )
)
```

### Contributors

> Holds address, phone and type of any contributor using [`contributor_id`] as
its identifier in other tables.

```{r read_contributor}
contributor <- read_okc(
  name = "contributor.csv",
  col_types = cols(
    .default = col_character(),
    contributor_id = col_integer(),
    type = col_integer()
  )
)
```

> Holds the different contributor types available (Individual, Business, Committee, Vendor)

```{r read_cont_type}
cont_type <- read_okc(
  name = "cont_type.csv",
  col_types = cols(
    cont_type = col_integer(),
    cont_desc = col_character()
  )
)
```

#### Individual Contributors

> Holds information relating to any individual contributor. Name, employer and occupation. Contributor id is the key that goes back to the contributor table and into either the transaction table for a transaction list or contributor aggregate table for tie ins to the `ethics_num` (committee) with aggregate totals.

```{r read_individual_cont}
individual_cont <- read_okc(
  name = "individual_cont.csv",
  col_types = cols(
    contributor_id = col_integer(),
    cont_fname = col_character(),
    cont_mname = col_character(),
    cont_lname = col_character(),
    employer = col_character(),
    occupation = col_character()
  )
)
```

#### Business Contributors

> Holds the business name (`cont_name`) and business activity of a business
contributor. Contributor id is the key that goes back to the contributor table
and into either the transaction table for a transaction list or contributor
aggregate table for tie ins to the `ethics_num` (committee) with aggregate
totals.

```{r read_business_cont}
business_cont <- read_okc(
  name = "business_cont.csv",
  col_types = cols(
    cont_id = col_double(),
    cont_name = col_character(),
    business_activity = col_character()
  )
)
```

#### Committee Contributors

> Holds the principal interest, contributor committee name and contributor FEC
number and committees ethics number for any committee contributors
(`contributor_id`). Contributor id is the key that goes back to the contributor
table and into either the transaction table for a transaction list or
contributor aggregate table for tie ins to the ethics_num (committee) with
aggregate totals.

```{r read_committee_cont}
committee_cont <- read_okc(
  name = "committee_cont.csv",
  col_types = cols(
    principal_interest = col_character(),
    id = col_integer(),
    ethics_num = col_integer(),
    committee_name = col_character(),
    cont_fec = col_character()
  )
)
```

#### Vendor Contributors

> Holds the Vendor Contributor name for any expenditure transaction

```{r read_vendor_cont}
vendor_cont <- read_okc(
  name = "vendor_cont.csv",
  col_types = cols(
    cont_id = col_integer(),
    cont_name = col_character()
  )
)
```

### Recipients

The information on the recipients of each transaction are held in other
databases.

#### Statement of Organization

The "SO-1" form applies to committees formed to support a political candidate.

```{r read_so1}
so1 <- read_okc(
  name = "so1.csv",
  col_types = cols(
    stricken_withdrawn = col_logical(),
    organization_date = col_date("%m/%d/%Y"),
    stmt_of_intent = col_date("%m/%d/%Y"),
    stricken_withdrawn_2 = col_date("%m/%d/%Y")
  )
)
```

The "SO-2" form applies to committees formed to support non-candidate issues.

```{r read_so2}
so2 <- read_okc(
  name = "so2.csv",
  col_types = cols(
    .default = col_character(),
    ethics_num = col_integer(),
    rep_num = col_integer(),
    affiliation_id = col_integer(),
    organization_date = col_date("%m/%d/%Y")
  )
)
```

#### Parties

> Has the different party affiliation types

```{r read_party}
party <- read_okc(
  name = "party.csv",
  col_types = cols(
    viewable = col_logical(),
    party_id = col_integer(),
    party_desc = col_character()
  )
)
```

#### Offices

> Description of office types (mainly for elections)

```{r read_office}
office <- read_okc(
  name = "office.csv",
  col_types = cols(
    id = col_integer(),
    office_desc = col_character()
  )
)
```

#### Districts

> List of the districts for elections

```{r read_district}
district <- read_okc(
  name = "district.csv",
  col_types = cols(
    district_id = col_integer(),
    district_desc = col_character()
  )
)
```

#### Candidates

> Holds the candidate name and birthdate tied to the specific ethics_num
(committee)

```{r read_candidate}
candidate <- read_okc(
  name = "candidate.csv",
  col_types = cols(
    .default = col_character(),
    ethics_num = col_integer(),
    birthdate = col_date("%Y%m%d")
  )
)
```

#### Lump Funds

> Holds lump fund information for the respective report_num

```{r read_lump_fund}
lump_fund <- read_okc(
  name = "lump_fund.csv",
  col_types = cols(
    rep_num = col_integer(),
    lump_amount = col_double(),
    lump_desc = col_character(),
    lump_code = col_integer(),
    lump_persons = col_integer(),
    lump_id = col_integer(),
    lump_date = col_date("%d-%b-%y"),
  )
)
```

### Report

> Holds all the `report_num` for all filed reports in the system from the SO1,
SO2s to all the C1R, C3R, C4R, and C5R reports. C6R reports are stored in the
c6r_report table. Contains the date the report was submitted, the `ethics_num`
(committee) that it ties to, period id, the report type, signature field, admin
entered (means the report was filed by administrator), the amended reference (if
null, is the latest report, if not then that report was amended to the
`report_num` that is displayed in that field.), the final flag determines if
that was the final report they will be filing and `supp_year` is just a field on
the form to show the year.

```{r read_report}
report <- read_okc(
  name = "report.csv",
  col_types = cols(
    ethics_num = col_integer(),
    rep_num = col_integer(),
    period_id = col_integer(),
    report_type = col_integer(),
    signature = col_character(),
    submitted_date = col_character(),
    admin_entered = col_integer(),
    amended_reference = col_integer(),
    final = col_logical(),
    supp_year = col_integer()
  )
)
```

> Description of each type of report available (SO1, SO2, C1R, C3R, C4R, C5R,
C6R)

```{r read_rep_type}
report_type <- read_okc(
  name = "report_type.csv",
  col_types = cols(
    report_type = col_integer(),
    report_description = col_character()
  )
)
```

## Join

Our primary interest is when a transaction was made, for how much, from whom,
and to whom. The transaction database contains the when and how much, but uses
keys to identify the who.

The contributor of a transaction (giving money) is identified by the `cont_id`
variable.

The recipient of a transaction (getting money) are the ones filing the report on
which each transaction appears, identifying by the `rep_num` variable. In the
database of reports, the filer of each report is identified with their
`ethics_id`.

By joining each transaction with the filer of the respective report, we can
identify the filer.

```{r join_recs}
okc <- left_join(
  x = transaction,
  y = report %>% select(rep_num, ethics_num), 
  by = "rep_num"
)
```

To improve the searchability of this database of transactions, we will add the
name and location of each contributor and recipient.

### Contributors

First, we will join the `contributor` table, which contains geographic data on
each contributor (city, state, zip), which the full tables of each contributor
type.

There are four types of contributors, each identified with different
`cont_*name` variables:

1. Individuals with `cont_fname`, `cont_mname`, and `cont_lname`.
    * With `cont_employer` and `cont_occupation`.
2. Businesses with a `cont_name`.
    * With `business_activity` describing the business type.
3. Committees with a `cont_name`.
    * with `cont_interest` and `ethics_num`.
4. Vendors with a `committee_name`.
    * with an OEC `ethics_num` ID.

It's important to note that the transactions database contains both
contributions _and_ expenditures reported by the filer. For expenditures, the
"contributor" is actually the vendor recipient of the money. These vendor
transactions will be filtered out.

```{r echo=FALSE}
cont_type %>% 
  mutate(
    table_name = paste0(tolower(cont_desc), "_cont"),
    file_name = md_code(paste0(table_name, ".csv")),
    nrow = comma(map_dbl(table_name, ~nrow(get(.))))
  ) %>% 
  select(-table_name) %>% 
  kable()
```

```{r join_conts, collapse=TRUE}
all_cont <- contributor %>%
  select(-phone, -ext) %>%  # 99% missing
  # add the type of contribution identifying the right table
  left_join(cont_type, by = c("type" = "cont_type")) %>% 
  # ignore vendor names from "any expenditure transaction"
  filter(contributor_id %out% vendor_cont$cont_id)  %>% 
  # add the names and details from each of the 3 types
  left_join(individual_cont, by = "contributor_id") %>% 
  left_join(business_cont, by = c("contributor_id" = "cont_id")) %>% 
  left_join(committee_cont, by = c("contributor_id" = "id")) %>% 
  select(-ethics_num, -cont_fec)
```

```{r}
comma(nrow(all_cont))
```

There appears to be more total contributors than listed in the `contributor`
database. There are `r nrow(individual_cont) - nrow(contributor)` more
_individual_ contributors alone than there are total rows in the `contributor`
database.

```{r cont_miss, collapse=TRUE}
nrow(individual_cont) - nrow(contributor)
mean(individual_cont$contributor_id %in% contributor$contributor_id)
```

### Recipients

When a committee is formed to receive contributions, the file a "Statement of
Organization" report. Committees formed to receive funds on behalf of a
candidate file an "SO-1" form, and non-candidate organizations file an "SO-2"
form.

These forms contain a lot of information, but we will extract only the
geographic information of each, so that we can better search the contributions
and expenditures in the transactions database.

First, we will create a new table of candidate committee information from the
SO-1 database.

```{r can_recs}
cand_recs <- so1 %>%
  left_join(candidate, by = "ethics_num") %>% 
  left_join(party, by = c("party_num" = "party_id")) %>% 
  left_join(office, by = c("office_num" = "id")) %>% 
  rename_with(
    ~paste("com", ., sep = "_"),
    c(street, city, state, zip)
  ) %>% 
  rename(com_name = comname) %>% 
  # multiple entries per ethics id, take only the first
  distinct() %>% 
  group_by(ethics_num) %>% 
  slice(1) %>% 
  ungroup() %>% 
  select(ethics_num, com_name, starts_with("com_"), office_desc, party_desc)
```

The same can be done with non-candidate committee recipients from SO-2 filings.

```{r com_recs}
comm_recs <- so2 %>% 
  rename(com_name = comname) %>% 
  rename_with(
    ~paste("com", ., sep = "_"),
    c(street, city, state, zip)
  ) %>%
  select(ethics_num, starts_with("com_")) %>%
  distinct() %>% 
  group_by(ethics_num) %>% 
  slice(1) %>% 
  ungroup()
```

Combine the two types of recipients into a single table that can be joined to
the transactions database along the `ethics_id` of each transaction's report
filer.

```{r bind_recs, collapse=TRUE}
all_rec <- bind_rows(cand_recs, comm_recs)
dim(all_rec)
n_distinct(all_rec$ethics_num) == nrow(all_rec)
```

There are `r nrow(all_rec)` unique committees that have filed SO-1 or
S0-2 reports, each identified by their unique `ethics_id` variable.

### Total Join

With our new tables of unique contributors and unique recipients, we can better
identify the parties to each transaction. We will join all three tables by their
respective `*_id` variables.

```{r}
okc <- transaction %>% 
  inner_join(report %>% select(rep_num, ethics_num), by = "rep_num") %>% 
  inner_join(all_cont, by = "contributor_id") %>% 
  inner_join(all_rec, by = "ethics_num")
```

```{r include=FALSE}
rm(
  all_contributors,
  all_recipients,
  candidates,
  parties,
  offices,
  contributors,
  individual_conts,
  business_conts,
  vendor_conts,
  committee_conts,
  committee_recs,
  transactions,
  so1, 
  so2,
  lump_funds,
  reports,
  cont_types,
  districts
)
```

## Explore

There are `r comma(nrow(okc))` rows of `r ncol(okc)` columns. Each record
represents a single Contributions...

```{r glimpse}
glimpse(okc)
tail(okc)
```

### Missing

Columns vary in their degree of missing values.

```{r na_count}
col_stats(okc, count_na)
```

We can flag any record missing a key variable needed to identify a transaction.

```{r na_flag}
key_vars <- c("date", "last", "amount", "committee")
okc <- flag_na(okc, all_of(key_vars))
sum(okc$na_flag)
```

```{r na_view}
okc %>% 
  filter(na_flag) %>% 
  select(all_of(key_vars))
```

### Duplicates

We can also flag any record completely duplicated across every column.

```{r dupe_flag}
okc <- flag_dupes(okc, -id)
sum(okc$dupe_flag)
```

```{r dupe_view}
okc %>% 
  filter(dupe_flag) %>% 
  select(all_of(key_vars))
```

### Categorical

```{r distinct_count}
col_stats(okc, n_distinct)
```

```{r distinct_plots, echo=FALSE}
explore_plot(okc, type)
```

### Amounts

```{r amount_summary}
summary(okc$amount)
mean(okc$amount <= 0)
```

These are the records with the minimum and maximum amounts.

```{r amount_minmax}
glimpse(okc[c(which.max(okc$amount), which.min(okc$amount)), ])
```

```{r hist_amount, echo=FALSE}
okc %>%
  ggplot(aes(amount)) +
  geom_histogram(fill = dark2["purple"]) +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(
    breaks = c(1 %o% 10^(0:6)),
    labels = dollar,
    trans = "log10"
  ) +
  labs(
    title = "Oklahoma Contributions Amount Distribution",
    caption = "Source: {source}",
    x = "Amount",
    y = "Count"
  )
```

### Dates

We can add the calendar year from `date` with `lubridate::year()`

```{r date_year}
okc <- mutate(okc, year = year(date))
```

```{r date_range}
min(okc$date)
sum(okc$year < 2000)
max(okc$date)
sum(okc$date > today())
```

```{r bar_year, echo=FALSE}
okc %>% 
  count(year) %>% 
  mutate(even = is_even(year)) %>% 
  ggplot(aes(x = year, y = n)) +
  geom_col(aes(fill = even)) + 
  scale_fill_brewer(palette = "Dark2") +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(breaks = seq(2000, 2020, by = 2)) +
  theme(legend.position = "bottom") +
  labs(
    title = "Oklahoma Contributions by Year",
    caption = "Source: {source}",
    fill = "Election Year",
    x = "Year Made",
    y = "Count"
  )
```

## Wrangle

To improve the searchability of the database, we will perform some consistent,
confident string normalization. For geographic variables like city names and
ZIP codes, the corresponding `campfin::normal_*()` functions are tailor made to 
facilitate this process.

### Address

For the street `addresss` variable, the `campfin::normal_address()` function
will force consistence case, remove punctuation, and abbreviate official 
USPS suffixes.

```{r address_norm}
okc <- okc %>% 
  unite(
    col = address_full,
    starts_with("address"),
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  mutate(
    address_norm = normal_address(
      address = address_full,
      abbs = usps_street,
      na_rep = TRUE
    )
  ) %>% 
  select(-address_full)
```

```{r address_view}
okc %>% 
  select(contains("address")) %>% 
  distinct() %>% 
  sample_n(10)
```

### ZIP

For ZIP codes, the `campfin::normal_zip()` function will attempt to create
valid _five_ digit codes by removing the ZIP+4 suffix and returning leading
zeroes dropped by other programs like Microsoft Excel.

```{r zip_norm}
okc <- okc %>% 
  mutate(
    zip_norm = normal_zip(
      zip = zip,
      na_rep = TRUE
    )
  )
```

```{r zip_progress}
progress_table(
  okc$zip,
  okc$zip_norm,
  compare = valid_zip
)
```

### State

Valid two digit state abbreviations can be made using the 
`campfin::normal_state()` function.

```{r state_norm}
okc <- okc %>% 
  mutate(
    state_norm = normal_state(
      state = state,
      abbreviate = TRUE,
      na_rep = TRUE,
      valid = valid_state
    )
  )
```

```{r state_view}
okc %>% 
  filter(state != state_norm) %>% 
  count(state, state_norm, sort = TRUE)
```

```{r state_progress}
progress_table(
  okc$state,
  okc$state_norm,
  compare = valid_state
)
```

### City

Cities are the most difficult geographic variable to normalize, simply due to
the wide variety of valid cities and formats.

#### Normal

The `campfin::normal_city()` function is a good start, again converting case,
removing punctuation, but _expanding_ USPS abbreviations. We can also remove
`invalid_city` values.

```{r city_norm}
norm_city <- okc %>% 
  distinct(city, state_norm, zip_norm) %>% 
  mutate(
    city_norm = normal_city(
      city = city, 
      abbs = usps_city,
      states = c("OK", "DC", "OKLAHOMA"),
      na = invalid_city,
      na_rep = TRUE
    )
  )
```

#### Swap

We can further improve normalization by comparing our normalized value
against the _expected_ value for that record's state abbreviation and ZIP code.
If the normalized value is either an abbreviation for or very similar to the
expected value, we can confidently swap those two.

```{r city_swap}
norm_city <- norm_city %>% 
  rename(city_raw = city) %>% 
  left_join(
    y = zipcodes,
    by = c(
      "state_norm" = "state",
      "zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_abb = is_abbrev(city_norm, city_match),
    match_dist = str_dist(city_norm, city_match),
    city_swap = if_else(
      condition = !is.na(match_dist) & (match_abb | match_dist == 1),
      true = city_match,
      false = city_norm
    )
  ) %>% 
  select(
    -city_match,
    -match_dist,
    -match_abb
  )
```

```{r city_rejoin}
okc <- left_join(
  x = okc,
  y = norm_city,
  by = c(
    "city_raw", 
    "state_norm", 
    "zip_norm"
  )
)
```

#### Refine

The [OpenRefine][or] algorithms can be used to group similar strings and replace
the less common versions with their most common counterpart. This can greatly
reduce inconsistency, but with low confidence; we will only keep any refined
strings that have a valid city/state/zip combination.

[or]: https://openrefine.org/

```{r city_refine}
good_refine <- okc %>% 
  mutate(
    city_refine = city_swap %>% 
      key_collision_merge() %>% 
      n_gram_merge(numgram = 1)
  ) %>% 
  filter(city_refine != city_swap) %>% 
  inner_join(
    y = zipcodes,
    by = c(
      "city_refine" = "city",
      "state_norm" = "state",
      "zip_norm" = "zip"
    )
  )
```

```{r city_count, echo=FALSE}
good_refine %>%
  count(
    state_norm, 
    zip_norm, 
    city_swap, 
    city_refine,
    sort = TRUE
  )
```

Then we can join the refined values back to the database.

```{r city_join}
okc <- okc %>% 
  left_join(good_refine) %>% 
  mutate(city_refine = coalesce(city_refine, city_swap))
```

#### Progress

Our goal for normalization was to increase the proportion of city values known
to be valid and reduce the total distinct values by correcting misspellings.

```{r city_progress, echo=FALSE}
many_city <- c(valid_city, extra_city)
progress <- progress_table(
  str_to_upper(okc$city_raw),
  okc$city_norm,
  okc$city_swap,
  okc$city_refine,
  compare = many_city
) %>% mutate(stage = as_factor(stage))
kable(progress, digits = 3)
```

You can see how the percentage of valid values increased with each stage.

```{r bar_progress, echo=FALSE}
raw_in <- percent(prop_in(okc$city_raw, valid_city))
progress %>% 
  ggplot(aes(x = stage, y = prop_in)) +
  geom_hline(yintercept = 0.99) +
  geom_col(fill = dark2["purple"]) +
  coord_cartesian(ylim = c(0.75, 1)) +
  scale_y_continuous(labels = percent) +
  labs(
    title = "Oklahoma City Normalization Progress",
    subtitle = glue("Raw at {raw_in} before conversion to uppercase"),
    x = "Stage",
    y = "Percent Valid"
  )
```

More importantly, the number of distinct values decreased each stage. We were
able to confidently change many distinct invalid values to their valid
equivalent.

```{r bar_distinct, echo=FALSE}
progress %>% 
  select(
    stage, 
    all = n_distinct,
    bad = n_diff
  ) %>% 
  mutate(good = all - bad) %>% 
  pivot_longer(c("good", "bad")) %>% 
  mutate(name = name == "good") %>% 
  ggplot(aes(x = stage, y = value)) +
  geom_col(aes(fill = name)) +
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  scale_y_continuous(labels = comma) +
  theme(legend.position = "bottom") +
  labs(
    title = "Oklahoma City Normalization Progress",
    subtitle = "Distinct values, valid and invalid",
    x = "Stage",
    y = "Distinct Values",
    fill = "Valid"
  )
```

## Conclude

Before exporting, we can remove the intermediary normalization columns and
rename all added variables with the `_clean` suffix.

```{r clean_select}
okc <- okc %>% 
  select(
    -city_norm,
    -city_swap,
    city_clean = city_refine
  ) %>% 
  rename_all(~str_replace(., "_norm", "_clean")) %>% 
  rename_all(~str_remove(., "_raw"))
```

```{r clean_glimpse}
glimpse(sample_n(okc, 50))
```

1. There are `r comma(nrow(okc))` records in the database.
1. There are `r comma(sum(okc$dupe_flag))` duplicate records in the database.
1. The range and distribution of `amount` and `date` seem reasonable.
1. There are `r comma(sum(okc$na_flag))` records missing key variables.
1. Consistency in geographic data has been improved with `campfin::normal_*()`.
1. The 4-digit `year` variable has been created with `lubridate::year()`.

## Export

Now the file can be saved on disk for upload to the Accountability server.

```{r clean_dir}
clean_dir <- dir_create(here("ok", "contribs", "data", "clean"))
clean_path <- path(clean_dir, "ok_contribs_clean.csv")
write_csv(okc, clean_path, na = "")
(clean_size <- file_size(clean_path))
file_encoding(clean_path) %>% 
  mutate(across(path, path.abbrev))
```

## Upload

We can use the `aws.s3::put_object()` to upload the text file to the IRW server.

```{r aws_upload, eval=FALSE}
aws_path <- path("csv", basename(clean_path))
if (!object_exists(aws_path, "publicaccountability")) {
  put_object(
    file = clean_path,
    object = aws_path, 
    bucket = "publicaccountability",
    acl = "public-read",
    show_progress = TRUE,
    multipart = TRUE
  )
}
aws_head <- head_object(aws_path, "publicaccountability")
(aws_size <- as_fs_bytes(attr(aws_head, "content-length")))
unname(aws_size == clean_size)
```

## Dictionary

The following table describes the variables in our final exported file:

```{r dict_make, echo=FALSE}
dict_raw <- tibble(
  var = md_code(names(okc)),
  type = md_code(map_chr(okc, typeof)),
  def = c(
    ""
  )
)
```

```{r dict_md, echo=FALSE}
(dict_md <- kable(
  x = dict_raw,
  format = "markdown",
  col.names = c("Column", "Type", "Definition")
))
```
