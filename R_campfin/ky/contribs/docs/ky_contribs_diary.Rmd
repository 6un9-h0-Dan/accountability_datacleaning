---
title: "Kentucky Contributions"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
fs::dir_create(here::here("ky", "contribs", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give
journalists, policy professionals, activists, and the public at large a simple
way to search across huge volumes of public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each
dataset row as a transaction. For each transaction there should be (at least) 3
variables:

1. All **parties** to a transaction.
2. The **date** of the transaction.
3. The **amount** of money involved.

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for entirely duplicated records.
1. Check ranges of continuous variables.
1. Is there anything blank or missing?
1. Check for consistency issues.
1. Create a five-digit ZIP Code called `zip`.
1. Create a `year` field from the transaction date.
1. Make sure there is data on both parties to a transaction.

## Packages

The following packages are needed to collect, manipulate, visualize, analyze,
and communicate these results. The `pacman` package will facilitate their
installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This
package contains functions custom made to help facilitate the processing of
campaign finance data.

```{r load_packages, message=FALSE, warning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  gluedown, # print markdown
  magrittr, # pipe operators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  rvest, # read html pages
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a
sub-directory of the more general, language-agnostic
[`irworkshop/accountability_datacleaning`][tap] GitHub repository.

The `R_campfin` project uses the [RStudio projects][rproj] feature and should be
run as such. The project also uses the dynamic `here::here()` tool for file
paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::here()
```

[tap]: https://github.com/irworkshop/accountability_datacleaning
[rproj]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects

## Data

The data is obtained from the [Kentucky Registry of Finance (KREF)][kref].

> The role of the Kentucky Registry of Election Finance is to assure the
integrity of the Commonwealth's electoral process by making certain there is
full public access to campaign financial data and financial disclosure reports,
and by administering Kentucky's campaign finance laws.

> The Registry ensures that information reports pertinent to election campaign
financing are filed on a timely basis and reviews this information for
completeness, accuracy, and compliance with campaign finance laws. The
Registry's regulatory function includes tracking of candidate and committee
election finance activities, audit functions, investigations, review of and
response to requests for advisory opinions, and adjudication of administrative
charges of violations of campaign finance laws.

[kref]: https://kref.ky.gov/about/Pages/default.aspx

The agency provides a data disclaimer:

> #### Data History
> The information contained in the Kentucky Registry of Election Finance’s
(KREF’s) online searchable database begins with financial records from 1998. The
records in the database are gathered from the financial reports submitted to the
Registry from candidates, Kentucky permanent committees (PACs), executive
committees, issues committees, and gubernatorial exploratory committees.
>
> Prior to 2000, all financial transactions were manually entered into the
computer system for PACs and executive committees. Currently, in order to
provide financial information in a timely manner, only summary records are
manually entered into the database for PAC and executive committee receipts and
disbursements. The Registry is currently analyzing electronic filing for PAC and
executive committees.
>
> All receipts records are entered into the database for candidates. Again, the
disbursement transactions for candidates are manually entered into the database
as summary records for the purpose of timely disclosure. However, if candidates
submit financial records by using electronic filing software, the disbursement
figures are electronically entered as detailed records.

## Import

Data can be imported into R using the [KREF search portal][search]. From the 
portal home, we can search contributions to all recipients using the menu on 
the left side of the page. By searching each year from 1998 to 2020 using the
"Date between" search boxes, we can obtain text file URLs.

Searching the dates from January 1 to December 31 leads you to a results page.
At the bottom of that page, navigate to the "Click here to Generate Extract
Files" link. On this next page, the "Download Receipts" link leads to a text
file.

[search]: http://www.kref.state.ky.us/krefsearch/

### Download

We can download these text files locally using the unique 32 digit hash
generated by each search.

```{r raw_dir}
raw_dir <- dir_create(here("ky", "contribs", "data", "raw"))
```

```{r raw_download}
raw_hash <- c(
  "536BDF1854264718A6794A1EB21C495A", # 1998
  "BB13FCC06504458C95AEABD6C24A1339", # 1999
  "813262A1C2964D839F8BD2C7CCDC346C", # 2000
  "FC012CDEA3454E9DADEE14A928A4B0DE", # 2001
  "2569F41D09E84BA5BBDAA04BDFFEB55C", # 2002
  "5AFF4758D1F44F418F75B4700CDAC46F", # 2003
  "A350DC7A10714842A4164F72D60AEE53", # 2004
  "75A183DAB94B4BB4B2EF29DCEA47A74C", # 2005
  "4A9873769E7F4754B4368C668422CFD5", # 2006
  "0192CDA8D0CA4E40BC5AD566AA178FE5", # 2007
  "AD81D90D7F7A4AFD8E2F6F646A248C1B", # 2008
  "E7CB4F17490B450F82C519E7C1049931", # 2009
  "7DBACDB86BB04212AB4CC509E5B420A2", # 2010
  "0B32B70D3EE247BF8A5F375767C2261B", # 2011
  "690293FE4BD746319B11DE5D67C7F934", # 2012
  "4E3A44B0C76A470BB98C0A2EBAE5F9EE", # 2013
  "3D2A196A811C449BAE86150517BFCB6F", # 2014
  "0C2BADADE69D4C298BE0A113DB144EF3", # 2015
  "24A64DA4A4A44238884B4A40419DB3AE", # 2016
  "9C7F122D87D04585BBC0F42B6C35E7B9", # 2017
  "67EEEB26FD154E8EA32199E02BFC119E", # 2018
  "FB9533DAFB074F37837FFAD94DC1AE59"  # 2019
)
```

```{r}
raw_base <- "http://www.kref.state.ky.us/krefsearch"
raw_names <- glue("/kref_csvfiles/{raw_hash}.TXT")
raw_urls <- str_c(raw_base, raw_names)
raw_paths <- path(raw_dir, glue("ky_contribs_{1998:2019}.txt"))
if (!all_files_new(raw_dir)) {
  download.file(raw_urls, raw_paths)
}
```

### Read

To read these files, we will have to consult the [record layout][layout].

[layout]: http://www.kref.state.ky.us/krefsearch/file_layout.htm

> **Description:** The text file contains the receipt information, extracted
from the financial reports submitted to the Registry of Election Finance. The
extract file is a delimited file, with each field separated by semicolons (`;`).

> **NOTE**: If an entry error was made and a semi-colon was keyed into a record,
this will result in erroneous file import.

```{r echo=FALSE, results='asis'}
record_layout <- read_html(str_c(raw_base, "file_layout.htm", sep = "/"))
record_layout <- record_layout %>% 
  html_node("table") %>%
  html_table(fill = TRUE) %>% 
  as_tibble() %>% 
  slice(-c(1:2)) %>% 
  remove_empty("cols")

notes <- remove_empty(record_layout[33:44, ], "cols")
notes$X2 <- str_replace_all(str_trim(str_squish(notes$X2)), "\"", "\'")
names(notes) <- c("note", "detail")
notes %>% 
  glue_data("{note}: {detail}") %>% 
  md_bullet()
layout <- remove_empty(record_layout[1:31, ], "cols")
layout <- mutate_all(layout, ~na_if(na_if(., "N/A"), ""))
names(layout) <- c("position", "field", "desc", "notes")
layout$field <- field_names <- layout$field %>% 
  make_clean_names() %>% 
  str_remove("transaction_") %>% 
  str_remove("_name") %>% 
  str_remove("name_") %>% 
  str_replace("^date_of_transaction$", "date") %>% 
  str_replace("^election_date$", "election") %>% 
  str_replace("^office_sought$", "office") %>% 
  str_replace("^location_of_office$", "location") %>% 
  str_replace("^report_due_date$", "due_date") %>% 
  str_replace("^congressional_district$", "district") %>% 
  str_replace("^form_of_transaction$", "form") %>% 
  str_replace("^party_affiliation$", "party")
layout$field <- md_code(layout$field)
md_table(layout)
```

```{r raw_fix}
for (f in raw_paths) {
  read_lines(f) %>% 
  str_remove("(?<=\\d{4};STATE SENATOR)\\s(?=;)") %>% 
  str_remove("(?<=\\d{4};MAYOR)\\s(?=;)") %>% 
  str_remove("(?<=\\d{4};CITY COMMISSIONER)\\s(?=;)") %>% 
  str_remove("(?<=\\d{4};CITY COUNCIL MEMBER)\\s(?=;)") %>% 
  str_remove("(?<=\\d{4};IND SCHOOL BOARD MEMBER)\\s(?=;)") %>% 
  str_remove("(?<=\\d{4};SOIL CONSERVATION OFFICER)\\s(?=;)") %>% 
  str_remove("(?<=^\\w{1,100};;;;)\\s(?=;)") %>% 
  str_remove("(?<=;)[^[:alnum:];]+(?=;)") %>% 
  str_remove_all(";(?=\\s)|(?<=\\s);") %>% 
  write_lines(f)
}
```

```{r raw_read}
# 1,013,816
kyc <- map_df(
  .x = raw_paths,
  .f = read_delim,
  delim = ";",
  escape_backslash = FALSE,
  escape_double = FALSE,
  col_names = field_names,
  col_types = cols(
    .default = col_character(),
    election = col_date_usa(),
    due_date = col_date_usa(),
    amount = col_double(),
    date = col_date_usa()
  ) 
)
```

## Explore

```{r glimpse}
head(kyc)
tail(kyc)
glimpse(sample_n(kyc, 20))
```

### Missing

```{r na_count}
col_stats(kyc, count_na)
```

```{r na_flag}
kyc <- kyc %>% flag_na(date, last, amount, committee)
sum(kyc$na_flag)
```

### Duplicates

```{r dupe_flag}
kyc <- flag_dupes(kyc, -id)
sum(kyc$dupe_flag)
```

```{r dupe_view}
kyc %>% 
  filter(dupe_flag) %>% 
  select(date, last, amount, committee)
```

### Categorical

```{r n_distinct}
col_stats(kyc, n_distinct)
```

### Continuous

#### Amounts

```{r ammount_summary}
summary(kyc$amount)
mean(kyc$amount <= 0)
```

```{r hist_amount, echo=FALSE}
kyc %>%
  ggplot(aes(amount)) +
  geom_histogram(fill = dark2["purple"]) +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(
    breaks = c(1 %o% 10^(0:6)),
    labels = dollar,
    trans = "log10"
  ) +
  labs(
    title = "Kentucky Contributions Amount Distribution",
    subtitle = "from 2000 to 2019",
    caption = "Source: {source}",
    x = "Amount",
    y = "Count"
  )
```

#### Dates

```{r date_year}
kyc <- mutate(kyc, year = year(date))
```

```{r date_range}
min(kyc$date)
sum(kyc$year < 2000)
max(kyc$date)
sum(kyc$date > today())
```

```{r bar_year, echo=FALSE}
kyc %>% 
  count(year) %>% 
  mutate(even = is_even(year)) %>% 
  ggplot(aes(x = year, y = n)) +
  geom_col(aes(fill = even)) + 
  scale_fill_brewer(palette = "Dark2") +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(breaks = seq(2000, 2020, by = 2)) +
  theme(legend.position = "bottom") +
  labs(
    title = "Kentucky Contributions by Year",
    caption = "Source: {source}",
    fill = "Election Year",
    x = "Year Made",
    y = "Count"
  )
```

## Wrangle

To improve the searchability of the database, we will perform some consistent,
confident string normalization. For geographic variables like city names and
ZIP codes, the corresponding `campfin::normal_*()` functions are tailor made to 
facilitate this process.

### Address

For the street `addresss` variable, the `campfin::normal_address()` function
will force consistence case, remove punctuation, and abbreviate official 
USPS suffixes.

```{r address_norm}
kyc <- kyc %>% 
  unite(
    col = address_full,
    starts_with("address"),
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  mutate(
    address_norm = normal_address(
      address = address_full,
      abbs = usps_street,
      na_rep = TRUE
    )
  ) %>% 
  select(-address_full)
```

```{r address_view}
kyc %>% 
  select(contains("address")) %>% 
  distinct() %>% 
  sample_n(10)
```

### ZIP

For ZIP codes, the `campfin::normal_zip()` function will attempt to create
valid _five_ digit codes by removing the ZIP+4 suffix and returning leading
zeroes dropped by other programs like Microsoft Excel.

```{r zip_norm}
kyc <- kyc %>% 
  mutate(
    zip_norm = normal_zip(
      zip = zip,
      na_rep = TRUE
    )
  )
```

```{r zip_progress}
progress_table(
  kyc$zip,
  kyc$zip_norm,
  compare = valid_zip
)
```

### State

Valid two digit state abbreviations can be made using the 
`campfin::normal_state()` function.

```{r state_norm}
kyc <- kyc %>% 
  mutate(
    state_norm = normal_state(
      state = state,
      abbreviate = TRUE,
      na_rep = TRUE,
      valid = valid_state
    )
  )
```

```{r state_view}
kyc %>% 
  filter(state != state_norm) %>% 
  count(state, sort = TRUE)
```

```{r state_progress}
progress_table(
  kyc$state,
  kyc$state_norm,
  compare = valid_state
)
```

### City

Cities are the most difficult geographic variable to normalize, simply due to
the wide variety of valid cities and formats.

#### Normal

The `campfin::normal_city()` function is a good start, again converting case,
removing punctuation, but _expanding_ USPS abbreviations. We can also remove
`invalid_city` values.

```{r city_norm}
kyc <- kyc %>% 
  mutate(
    city_norm = normal_city(
      city = city, 
      abbs = usps_city,
      states = c("KY", "DC", "KENTUCKY"),
      na = invalid_city,
      na_rep = TRUE
    )
  )
```

#### Swap

We can further improve normalization by comparing our normalized value
against the _expected_ value for that record's state abbreviation and ZIP code.
If the normalized value is either an abbreviation for or very similar to the
expected value, we can confidently swap those two.

```{r city_swap}
kyc <- kyc %>% 
  rename(city_raw = city) %>% 
  left_join(
    y = zipcodes,
    by = c(
      "state_norm" = "state",
      "zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_abb = is_abbrev(city_norm, city_match),
    match_dist = str_dist(city_norm, city_match),
    city_swap = if_else(
      condition = !is.na(match_dist) & match_abb | match_dist == 1,
      true = city_match,
      false = city_norm
    )
  ) %>% 
  select(
    -city_match,
    -match_dist,
    -match_abb
  )
```

#### Refine

The [OpenRefine] algorithms can be used to group similar strings and replace the
less common versions with their most common counterpart. This can greatly 
reduce inconsistency, but with low confidence; we will only keep any refined
strings that have a valid city/state/zip combination.

[or]: https://openrefine.org/

```{r city_refine}
good_refine <- kyc %>% 
  mutate(
    city_refine = city_swap %>% 
      key_collision_merge() %>% 
      n_gram_merge(numgram = 1)
  ) %>% 
  filter(city_refine != city_swap) %>% 
  inner_join(
    y = zipcodes,
    by = c(
      "city_refine" = "city",
      "state_norm" = "state",
      "zip_norm" = "zip"
    )
  )
```

```{r city_count, echo=FALSE}
good_refine %>%
  count(
    state_norm, 
    zip_norm, 
    city_swap, 
    city_refine,
    sort = TRUE
  )
```

Then we can join the refined values back to the database.

```{r city_join}
kyc <- kyc %>% 
  left_join(good_refine) %>% 
  mutate(city_refine = coalesce(city_refine, city_swap))
```

#### Progress

```{r city_progress, echo=FALSE}
many_city <- c(valid_city, extra_city)
progress <- progress_table(
  str_to_upper(kyc$city_raw),
  kyc$city_norm,
  kyc$city_swap,
  compare = many_city
) %>% mutate(stage = as_factor(stage))
kable(progress, digits = 3)
```

You can see how the percentage of valid values increased with each stage.

```{r bar_progress, echo=FALSE}
raw_in <- percent(prop_in(kyc$city_raw, valid_city))
progress %>% 
  ggplot(aes(x = stage, y = prop_in)) +
  geom_hline(yintercept = 0.99) +
  geom_col(fill = dark2["purple"]) +
  coord_cartesian(ylim = c(0.75, 1)) +
  scale_y_continuous(labels = percent) +
  labs(
    title = "Kentucky City Normalization Progress",
    subtitle = glue("Raw at {raw_in} before conversion to uppercase"),
    x = "Stage",
    y = "Percent Valid"
  )
```

More importantly, the number of distinct values decreased each stage. We were
able to confidently change many distinct invalid values to their valid
equivalent.

```{r bar_distinct, echo=FALSE}
progress %>% 
  select(
    stage, 
    all = n_distinct,
    bad = n_diff
  ) %>% 
  mutate(good = all - bad) %>% 
  pivot_longer(c("good", "bad")) %>% 
  mutate(name = name == "good") %>% 
  ggplot(aes(x = stage, y = value)) +
  geom_col(aes(fill = name)) +
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  scale_y_continuous(labels = comma) +
  theme(legend.position = "bottom") +
  labs(
    title = "Kentucky City Normalization Progress",
    subtitle = "Distinct values, valid and invalid",
    x = "Stage",
    y = "Distinct Values",
    fill = "Valid"
  )
```

## Conclude

```{r clean_select}
kyc <- kyc %>% 
  select(
    -city_norm,
    -city_swap,
    city_clean = city_refine
  ) %>% 
  rename_all(~str_replace(., "_norm", "_clean"))
```

```{r clean_glimpse}
glimpse(sample_n(kyc, 20))
```

1. There are `r comma(nrow(kyc))` records in the database.
1. There are `r comma(sum(kyc$dupe_flag))` duplicate records in the database.
1. The range and distribution of `amount` and `date` seem reasonable.
1. There are `r comma(sum(kyc$na_flag))` records missing ....
1. Consistency in geographic data has been improved with `campfin::normal_*()`.
1. The 4-digit `year` variable has been created with `lubridate::year()`.

## Export

```{r clean_dir}
clean_dir <- dir_create(here("ky", "contribs", "data", "clean"))
```

```{r clean_write}
write_csv(
  x = kyc,
  path = path(clean_dir, "ky_contribs_clean.csv"),
  na = ""
)
```

