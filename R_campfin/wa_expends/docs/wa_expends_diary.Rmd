---
title: "Data Diary"
subtitle: "Washington Expenditures"
author: "Kiernan Nicholls"
date: "`r format(Sys.time())`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
```

## Objectives

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called ZIP5
1. Create a YEAR field from the transaction date
1. For campaign donation data, make sure there is both a donor AND recipient

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

```{r p_load, message=FALSE, warning=FALSE, error=FALSE}
pacman::p_load(
  stringdist, # levenshtein value
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe opperators
  RSocrata, # read SODA APIs
  janitor, # dataframe clean
  zipcode, # clean & databse
  batman, # parse yes & no
  refinr, # cluster & merge
  rvest, # scrape website
  knitr, # knit documents
  here, # locate storage
  fs # search storage 
)
```

```{r fix_fun, echo=FALSE}
here <- here::here
"%out%" <- Negate("%in%")
print_all <- function(df) df %>% print(n = nrow(.)) 
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory
of the more general, language-agnostic `irworkshop/accountability_datacleaning` 
[GitHub repository](https://github.com/irworkshop/accountability_datacleaning).

The `R_campfin` project uses the 
[RStudio projects](https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects)
feature and should be run as such. The project also uses the dynamic 
[`here::here()`](https://github.com/jennybc/here_here) tool for
file paths relative to _your_ machine.

```{r where_here, collapse=TRUE}
# where was this document knit?
here::here()
```

## Data

This dataset comes courtesy of the State of 
[Washington Public Disclosure Commission](http://www.pdc.wa.gov), access through the 
[data.wa.gov](https://data.wa.gov) portal.

The resource is named `exenditures_by_candidates_and_political_committees` and covers the last 10
years of data with daily updates. Each records represents a single "Expenditure by a campaign or
committee."

### About

> This dataset contains expenditures made by Washington State Candidates and Political Committees
for the last 10 years as reported to the PDC on forms C3, C4, Schedule C and their electronic
filing equivalents.
> 
> In-kind contributions are included in this data set as they are considered as both a contribution
and expenditure. In-kind contributions are also included in the data set "Contributions to
Candidates and Political Committees."
> 
> For candidates, the number of years is determined by the year of the election, not necessarily
the year the expenditure was reported. For political committees, the number of years is determined
by the calendar year of the reporting period.
> 
> Candidates and political committees choosing to file under "mini reporting" are not included in
this dataset. See WAC 390-16-105 for information regarding eligibility.
> 
> This dataset is a best-effort by the PDC to provide a complete set of records as described
herewith and may contain incomplete or incorrect information. The PDC provides access to the
original reports for the purpose of record verification.
> 
> Descriptions attached to this dataset do not constitute legal definitions; please consult RCW
42.17A and WAC Title 390 for legal definitions and additional information regarding political
finance disclosure requirements.
> 
> CONDITION OF RELEASE: This publication constitutes a list of individuals prepared by the
Washington State Public Disclosure Commission and may not be used for commercial purposes. This
list is provided on the condition and with the understanding that the persons receiving it agree to
this statutorily imposed limitation on its use. See RCW 42.56.070(9) and AGO 1975 No. 15.

### Variables

The [Data.WA API page](https://dev.socrata.com/foundry/data.wa.gov/ukxb-bc7h) provides definitions
for the variables provided in this dataset.

`id`:

> PDC internal identifier that corresponds to a single expenditure record. When combined with the
origin value, this number uniquely identifies a single row.

`report_number`:

> PDC identifier used for tracking the individual form C4 . Multiple expenditures will have the
same report number when they were reported to the PDC at the same time. The report number is unique
to the report it represents. When a report is amended, a new report number is assigned that
supersedes the original version and the original report records are not included in this dataset.

`origin`:

> This field shows from which filed report-type the data originates. A/LE50 refers to non-itemized
expenditures of $50 and less per expenditure. A/GT50 refers to itemized expenditures greater than
$50 per expenditure. A/LE50 and A/GT50 are both reported on schedule A of form C4
>
> To view the different report types and forms browse to:https://www.pdc.wa.gov/learn/forms

`filer_id`:

> The unique id assigned to a candidate or political committee. The filer id is consistent across
election years with the exception that an individual running for a second office in the same
election year will receive a second filer id. There is no correlation between the two filer ids.
For a candidate and single-election-year committee such as a ballot committee, the combination of
filerid and electionyear uniquely identifies a campaign.

`type`:

> Indicates if this record is for a candidate or a political committee. In the case of a political
committee, it may be either a continuing political committee, party committee or single election
year committee.

`filer_name`:

> The candidate or committee name as reported on the form C1 candidate or committee registration
form. The name will be consistent across all records for the same filer id and election year but
may differ across years due to candidates or committees changing their name.

`id`:

> This field represents the first name, as reported by the filer. This field may appear blank if
the name is not reported or if a filing entity has a single name, such as a PAC or other political
committee. Note that this data appears as represented by the filer and may not be consistent from
one reporting period to another.

`last_name`:

> This field represents the last name, as reported by the filer. The field may also contain the
full name of a filing entity that is registered under one name, such as a PAC or other filing
committee. Note that this data appears as represented by the filer and may not be consistent from
one reporting period to another.

`office`:

> The office sought by the candidate. Does not apply to political committees.

`legislative_district`:

> The Washington State legislative district. This field only applies to candidates where the office
is "state senator" or "state representative."

`position`:

> The position associated with an office. This field typically applies to judicial and local office
that have multiple positions or seats. This field does not apply to political committees.

`party`:

> The political party as declared by the candidate or committee on their form C1 registration.
Contains only "Major parties" as recognized by Washington State law.

`ballot_number`:

> If the committee is a Statewide Ballot Initiative Committee a ballot number will appear once a
ballot number is assigned by the Secretary of State. Local Ballot Initiatives will not have a
ballot number. This field will contain a number only if the Secretary of State issues a number.

`for_or_against`:

> Ballot initiative committees are formed to either support or oppose an initiative. This field
represents whether a committee “Supports” or “Opposes” a ballot initiative.

`jurisdiction_*`:

> The political jurisdiction associated with the office of a candidate.

> The county associated with the jurisdiction of a candidate. Multi-county jurisdictions as
reported as the primary county. This field will be empty for political committees and when a
candidate jurisdiction is statewide.

> The type of jurisdiction this office is: Statewide, Local, etc.

`election_year`:

> The election year in the case of candidates and single election committees. The reporting year in
the case of continuing political committees.

`amount`:

> The amount of the expenditure or in-kind contribution. In-kind contributions are both a
contribution and an expenditure and represented in both the contributions and expenditures data.

`itemized_or_non_itemized`:

> A record for an itemized expenditure represents a single expenditure. A record for a non-itemized
expenditure represents one or more expenditures where the individual expenditures are less than the
limit for itemized reporting. In this case the record is the aggregate total for the reporting
period.

`expenditure_date`:

> The date that the expenditure was made or the in-kind contribution was received. See the metadata
for the origin and amount field regarding in-kind contributions.

`code`:

> The type of expenditure. The values displayed are human readable equivalents of the type codes reported on the form C4 schedule A. Please refer to the form for a listing of all codes. Itemized expenditures are generally required to have either a code or a description but may be required to have both. Non-itemized expenditures do not have a description. 

`recipient_name`:

> The name of the individual or vendor paid as reported. The names appearing here have not been normalized and the same entity may be represented by different names in the dataset. Non-itemized expenditures of $50 or less will have a recepient_name of EXPENSES OF $50 OR LESS and origin of A/LE50, and all address fields will be empty.

`recipient_*`:

> The street address of the individual or vendor paid as reported.

> The city of the individual or vendor paid as reported.

> The state of the individual or vendor paid as reported.

> The zip code of the individual or vendor paid as reported.

`url`:

> A link to a PDF version of the original report as it was filed to the PDC.

`recipient_location`:

> The geocoded location of the individual or vendor paid as reported. The quality of the geocoded
location is dependent on how many of the address fields are available and is calculated using a
third-party service. The PDC has not verified the results of the geocoding. Please refer to the
recipient_name field for more information regarding address fields.

## Read

> The [Socrata Open Data API (SODA)](http://dev.socrata.com/) provides programmatic access to this
dataset including the ability to filter, query, and aggregate data. For more more information, view
the [API docs for this dataset](https://dev.socrata.com/foundry/data.wa.gov/ukxb-bc7h) or visit our
[developer portal](http://dev.socrata.com/)

If an _recent_ version of the file doesn't exist locally, the `RSocrata::read.socrate()` function
can read the SODA dataset directly from the API into R.

```{r read_data}
wa_filename <- here(
  "wa_expends", "data", "raw", 
  "exenditures_by_candidates_and_political_committees.csv"
)  
if (file.exists(wa_filename) & as_date(file.mtime(wa_filename)) == today()) {
  wa <- read_csv(
    file = wa_filename,
    col_types = cols(.default = col_character())
  )
  read_from_soda = FALSE
} else {
  wa <- as_tibble(read.socrata("https://data.wa.gov/resource/ukxb-bc7h.json"))
  read_from_soda = TRUE
}
wa$amount <- parse_number(wa$amount)
wa$election_year <- parse_number(wa$election_year)
wa$expenditure_date <- as_date(wa$expenditure_date)
```

If the file had to be downloaded from the SODA API, save a copy of the raw data locally. Each
`recipient_location.coordinates` value is a list type, so they will have to be converted to
character vectors before being saved as a flat text file.

```{r write_raw}
dir_create(here("wa_expends", "data", "raw"))
if (read_from_soda) {
  wa %>% 
    mutate(recipient_location.coordinates = as.character(recipient_location.coordinates)) %>% 
    write_csv(
      path = wa_filename,
      na = ""
    )
}
```

Before working with the data in R, some binary character type variables will be converted to
logical variables. The coordinates character string will also be separated and converted to numeric
latitude and longitude variables.s

```{r parse_vars}
wa <- wa %>% 
  separate(
    col = recipient_location.coordinates,
    into = c("recipient_longitude", "recipient_latitude"),
    sep = ",\\s",
    remove = TRUE
  ) %>% 
  mutate(
    recipient_longitude = as.double(str_remove(recipient_longitude, "c\\(")),
    recipient_latitude = as.double(str_remove(recipient_latitude, "\\)")),
    expenditure_itemized = itemized_or_non_itemized == "Itemized",
    filer_supports = for_or_against == "For",
  ) %>% 
  select(
    -itemized_or_non_itemized,
    -for_or_against
  )
```

## Explore

There are `r nrow(wa)` records of `r length(wa)` variables in the full database.

```{r glimpse}
sample_frac(wa)
glimpse(sample_frac(wa))
```

### Distinct

The variables range in their degree of distinctness.

The `id` is `r scales::percent(n_distinct(wa$id)/nrow(wa))` distinct and can be used to
identify a unique transaction.

```{r n_distinct}
wa %>% 
  map(n_distinct) %>% 
  unlist() %>% 
  enframe(name = "variable", value = "n_distinct") %>% 
  mutate(prop_distinct = round(n_distinct / nrow(wa), 4)) %>%
  print(n = length(wa))
```

We can explore the distribution of the least distinct values with `ggplot2::geom_bar()`.

```{r plot_origin_bar, echo=FALSE}
ggplot(wa) + 
  geom_bar(aes(origin))
```

```{r plot_type_bar, echo=FALSE}
ggplot(wa) + 
  geom_bar(aes(type))
```

```{r plot_party_bar, echo=FALSE}
ggplot(wa) + 
  geom_bar(aes(party)) + 
  coord_flip()
```

```{r plot_jurisdiction_bar, echo=FALSE}
ggplot(wa) + 
  geom_bar(aes(jurisdiction_type))
```

```{r plot_election_year_bar, echo=FALSE}
ggplot(wa) + 
  geom_bar(aes(election_year))
```

```{r plot_itemized_bar, echo=FALSE}
ggplot(wa) + 
  geom_bar(aes(expenditure_itemized))
```

```{r plot_code_party, echo=FALSE}
wa %>%
  filter(party %in% c("DEMOCRAT", "REPUBLICAN", NA)) %>% 
  group_by(party, code) %>% 
  summarise(mean = mean(amount)) %>%
  arrange(code) %>% 
  ggplot(aes(code, mean)) +
  geom_col(aes(fill = party)) +
  facet_wrap(~party) +
  coord_flip() +
  scale_y_continuous(labels = scales::dollar) +
  theme(legend.position = "none") +
  labs(
    title = "Washington State Campaign Expenditures",
    subtitle = "NA for Non-Candidate Campaigns",
    caption = "Source: data.wa.gov/d/tijg-9zyp",
    y = "Mean Expenditure",
    x = "Expenditure Type"
  )
```

```{r plot_supports_bar, echo=FALSE}
wa %>% 
  filter(!is.na(filer_supports)) %>% 
  ggplot(aes(filer_supports)) + 
  geom_bar()
```

```{r plot_office_bar, echo=FALSE}
wa %>% 
  filter(!is.na(office)) %>%  
  count(office) %>% 
  arrange(desc(n)) %>% 
  slice(1:10) %>% 
  ggplot() + 
  geom_col(aes(office, n)) + 
  coord_flip()
```

### Missing

The variables also vary in their degree of values that are `NA` (missing).

```{r count_na}
wa %>% 
  map(function(var) sum(is.na(var))) %>% 
  unlist() %>% 
  enframe(name = "variable", value = "n_na") %>% 
  mutate(prop_na = n_na / nrow(wa)) %>% 
  print(n = length(wa))
```

We will flag any records with missing values in the key variables used to identify an expenditure.

```{r na_flag}
wa <- wa %>% 
  mutate(
    na_flag = is.na(expenditure_date) | is.na(recipient_name)
  )

wa %>% 
  filter(na_flag) %>%
  sample_frac() %>% 
  select(
    na_flag,
    id, 
    report_number,
    filer_name,
    recipient_name,
    amount,
    expenditure_date
    )
```

### Duplicates

There are no completely duplicate rows, as each record has a unique `id` variable.

```{r id_dupes, collapse=TRUE}
n_distinct(wa$id)/nrow(wa)
```

There are, however, records that are otherwise complete duplicates. It's possible that two
expenditures might be made by filer, to the same recipient, on the same day, for the same amount
but we will flag them with a logical `dupe_flag` variable not the less.

Using `janitor::get_dupes()`, we can create a table of records with duplicate filer, recipient,
date, _and_ amount values.

```{r get_dupes, collapse=TRUE}
wa_dupes <- wa %>% 
  get_dupes(
    filer_name,
    recipient_name,
    expenditure_date,
    amount
    ) %>% 
  mutate(dupe_flag = TRUE) %>%
  select(id, dupe_flag)

nrow(wa_dupes)
```

Then we join the table of duplicate records back onto the original dataset, with a new variable 
marking each duplicate row.

```{r flag_dupes, message=FALSE, warning=FALSE}
wa <- wa %>% 
  left_join(wa_dupes, by = "id") %>% 
  mutate(dupe_flag = !is.na(dupe_flag))
```

```{r count_dupes}
wa %>% 
  filter(dupe_flag) %>% 
  select(
    id,
    filer_name,
    recipient_name,
    expenditure_date,
    amount,
    code
  )
```

Many of these duplicate records have an `amount` value of zero, meaning they are likely
corrections to previous expenditures.

```{r plot_dupes_amount, echo=FALSE}
wa %>% 
  filter(dupe_flag) %>% 
  distinct() %>% 
  ggplot() + 
  geom_histogram(aes(amount))
```

### Ranges

The range of continuous variables will need to be checked for data integrity. There are only two
quasi-continuous variables, the `amount` and `expenditure_date`

We can checl the distribution of continuous variables with `ggplot2::geom_histogram()`

#### Transaction Amounts

The middle range for `amount` seems reasonable enough.
`r scales::percent(mean(wa$amount < 0))` percent of `amount` values are less than zero. 

```{r amount_range, collapse=TRUE}
summary(wa$amount)
tabyl(wa$amount > 0)
```

Most expenditures are for relatively little amount.

```{r plot_amt_nonlog, echo=FALSE}
ggplot(wa, aes(amount)) + 
  geom_histogram() + 
  scale_y_log10() +
  scale_x_continuous(labels = scales::dollar) +
  geom_hline(yintercept = 10)
```

```{r plot_party_hist, echo=FALSE}
ggplot(wa, aes(amount)) + 
  geom_histogram(aes(fill = party)) + 
  scale_y_log10() +
  scale_x_continuous(labels = scales::dollar, trans = "log10") +
  scale_fill_manual(
    guide = FALSE,
    values = c(
      "brown", 
      "royalblue", 
      "forestgreen", 
      "gold",
      "mediumpurple", 
      "#999999", 
      "firebrick",
      "black"
    )
  ) +
  geom_vline(xintercept = 100000) +
  facet_wrap(~party)
```

```{r plot_party_box, echo=FALSE}
ggplot(wa, aes(party, amount)) + 
  geom_boxplot(aes(fill = party), varwidth = TRUE) + 
  scale_y_continuous(labels = scales::dollar, trans = "log10") +
  scale_fill_manual(
    guide = FALSE,
    values = c(
      "brown", 
      "royalblue", 
      "forestgreen", 
      "gold",
      "mediumpurple", 
      "#999999", 
      "firebrick",
      "black"
    )
  ) +
  geom_hline(yintercept = 100000)
```

Below are the smallest and largest expenditures.

```{r glimpse_min_max}
glimpse(wa %>% filter(amount == min(amount, na.rm = T)))
glimpse(wa %>% filter(amount == max(amount, na.rm = T)))
```

We can view the link provided in the `url` variable to see the smallest expenditure is a correction
to an expenditure to Costco previously reported as \$8,929,810 that should have been \$6,429,810.
Interestingly, this same report shows a _contribution_ from the same Costco for the exact same
amount with the exact same correction. There is no description for the correction.

Using the `url` from the maximum report, the \$5,000,000 expenditure has "contribution" listed in
the "Purpose of Expense" box with nothing put in the spot for "Code" meant to identify the record
as a contribution or expenditure.

These two sample reports can be found as PDF files in the `data/` directory.

### Transaction Dates

There are a number of records with incorrect `expenditure_date` variables. There are no records
with expenditures made in the future, but there are a number of suspiciously old expenditures.

```{r date_future, collapse=TRUE}
max(wa$expenditure_date, na.rm = TRUE)
sum(wa$expenditure_date > today(), na.rm = T)
```

PDC claims that the dataset covers the last 10 years of data, but there are thousands of records
older than that, with one from `r year(min(wa$expenditure_date, na.rm = TRUE))`. The report
containing that expenditure was filed in 2010 and can be found as PDF in the `data/` directory.
That one report is the only one with an expenditure date before 2000, the rest appear to be
correct dates simply outside the expected time span.

```{r date_past, collapse=TRUE}
min(wa$expenditure_date, na.rm = TRUE)
sum(year(wa$expenditure_date) < 2007, na.rm = T)
```

```{r plot_exp_year, echo=FALSE}
wa %>% 
  count(year = year(expenditure_date)) %>% 
  ggplot(aes(year, n)) +
  geom_col() +
  coord_cartesian(xlim = c(2000, 2020)) +
  geom_vline(xintercept = 2008)
```

To better track expenditures in the TAP database, we will create a `expenditure_year` variable from
the previously parsed `expenditure_date` using `lubridate::year()`.

```{r add_year}
wa <- wa %>% 
  mutate(expenditure_year = year(expenditure_date))
```

## Clean

### Address

The `recipient_address` variable will be minimally cleaned by removing punctuation and fixing
white-space.

```{r}
wa <- wa %>% 
  mutate(
    address_clean = recipient_address %>% 
      str_to_upper() %>% 
      # remove punct and numbers
      str_replace("-", " ") %>% 
      str_remove_all("[:punct:]") %>% 
      str_trim() %>% 
      str_squish() %>% 
      na_if("") %>% 
      na_if("NA")
  )
```

### Zipcode

We can clean the `recipient_zip` variable using the `zipcodes::clean.zipcodes()` function, which
strips the ZIP+4 digits and adds leading zeroes to three or four digit strings. We will also make
some common invalid zips `NA`.

```{r zipcode_data, echo=FALSE}
data("zipcode")
source(here("R", "prep_city.R"))
zipcode <-
  as_tibble(zipcode) %>% 
  select(city, state, zip) %>% 
  mutate(city = prep_city(city))
```

```{r clean_zipcodes}
wa <- wa %>% 
  mutate(zip_clean = recipient_zip %>% 
           clean.zipcodes() %>% 
           na_if("00000") %>% 
           na_if("11111") %>% 
           na_if("99999")
  )

wa$zip_clean[which(nchar(wa$zip_clean) != 5)] <- NA
```

### State

Using comprehensive list of state abbreviations in the Zipcodes database, we can isolate invalid
`recipient_state` values and manually correct them.

```{r valid_state, collapse=TRUE}
valid_state <- c(unique(zipcode$state), "AB", "BC", "MB", "NB", "NL", "NS", "ON", "PE", "QC", "SK")
length(valid_state)
setdiff(valid_state, state.abb)
```

```{r view_states}
wa %>% 
  filter(recipient_state %out% valid_state) %>% 
  filter(!is.na(recipient_state)) %>% 
  select(
    id,
    recipient_address,
    recipient_city,
    recipient_state,
    recipient_zip
  ) %>% 
  print_all()
```

If the `recipient_state` abbreviation is invalid, use the `recipient_city` and `recipient_zip`
values for that record to manually correct the abbreviation where possible. If it can't be manually
corrected, make the value `NA`.

```{r}
wa$state_clean <- wa$recipient_state %>% 
  str_replace("QA", "WA") %>% # add match
  str_replace("SW", "WA") %>% # add match 
  str_replace("TE", "TX") %>% # add match
  str_replace("CN", "AB") %>% # calgary
  str_remove("[:punct:]") %>% 
  na_if("") %>% 
  na_if("RE") %>% # requested
  na_if("98") %>% # WA zip
  na_if("99") %>% # WA zip
  na_if("SH") %>% # hong kong
  na_if("FR") %>% # france
  na_if("OT") %>% # overseas
  na_if("HR") %>% # hungary
  na_if("UK") %>% # united kingdom
  na_if("IR") %>% # ireland
  na_if("IS")     # israel
```

### City

Cleaning city values is the most complicated. This process involves four steps:

1. Prepare raw city values by removing invalid data and reducing inconsistencies
1. Match prepared city values with the _actual_ city name of that record's ZIP code
1. Swap prepared city values with the ZIP code match _if_ only 1 edit is needed
1. Refine swapped city values with key collision and n-gram fingerprints

#### Prep City

The first step in cleaning city names is to reduce inconsistencies. The custom `city_prep()`
function found in the `R/` sub-directory of this root project performs the bulk of our preparation.
In short, the function (1) removes punctuation, numbers, and state abbreviations, (2) expands
directional and geographic abbreviations, and (3) catches common `NA` strings.

```{r prep_city}
source(here("R", "prep_city.R"))
wa <- wa %>% 
  mutate(
    city_prep = prep_city(
      cities = recipient_city,
      na = read_lines(here("R", "na_city.csv")),
      abbs = c("WA", "OR", "ID", "DC", "BC")
    )
  )
```

#### Match and Swap City

The second step will be to compare the new `city_prep` value to the _actual_ city value for that
record's `zip_clean` value. If the `city_prep` is very similar to the expected city name for that
ZIP code, we can make that change.

```{r match_dist}
wa <- wa %>%
  left_join(zipcode, by = c("state_clean" = "state", "zip_clean" = "zip")) %>%
  rename(city_match = city) %>%
  mutate(
    match_dist  = stringdist(city_prep, city_match),
    city_swap = if_else(match_dist == 1, city_match, city_prep)
  )
```

#### Refine City

Now that we've prepared out city values and made the most obvious changes, we can use the
OpenRefine algorithms to cluster similar values and merge them together. This can be done using the
`refinr::key_collision_merge()` and `refinr::n_gram_merge()` functions on our prepared and swapped
city data.

```{r valid_city}
valid_city <- c(
  unique(zipcode$city), 
  "SPOKANE VALLEY",
  "TUKWILA", 
  "BURIEN", 
  "SEATAC", 
  "LAKE FOREST PARK",
  "NORMANDY PARK",
  "FIRCREST"
  )
```

We will create a new table with these refined values.

```{r view_refine}
wa_refined <- wa %>%
  filter(state_clean == "WA") %>% 
  filter(match_dist != 1) %>% 
  mutate(
    city_refine = city_swap %>% 
      key_collision_merge(dict = valid_city) %>% 
      n_gram_merge(numgram = 1),
    refined = (city_swap != city_refine)
  ) %>% 
  filter(refined) %>% 
  select(
    id,
    state_clean,
    zip_clean,
    recipient_city,
    city_prep,
    city_match,
    match_dist,
    city_swap,
    city_refine,
  ) %>% 
  rename(
    state = state_clean,
    zip = zip_clean,
    city_raw = recipient_city
  )
```

#### Review Refined City

```{r most_refined}
wa_refined %>% 
  count(city_swap, city_refine) %>% 
  arrange(desc(n))
```

The key to the refine algorithms is clustering rare values with their more common similar values.
We can count how often the original value appears and compare it to the frequency of the refined
value.

```{r count_refined}
refined_values <- unique(wa_refined$city_refine)
count_refined <- tibble(
  city_refine = refined_values, 
  refine_count = NA
)

for (i in seq_along(refined_values)) {
  count_refined$refine_count[i] <- sum(str_detect(wa$city_swap, refined_values[i]), na.rm = TRUE)
}

swap_values <- unique(wa_refined$city_swap)
count_swap <- tibble(
  city_swap = swap_values, 
  swap_count = NA
)

for (i in seq_along(swap_values)) {
  count_swap$swap_count[i] <- sum(str_detect(wa$city_swap, swap_values[i]), na.rm = TRUE)
}
```

The least frequent refined values are the ones of which we should be most suspicious. The more
frequent a refined value appears compared to it's original value, the more confident the algorithm
can be in making the change. We should manually check any refined value with a small count.
Furthermore, some refined values appear _less_ often than their original value because their
fingerprint matches an entry in our dictionary (e.g., "Lake Forrest" vs "Forrest Lake").

```{r distinct_refined}
wa_refined %>% 
  left_join(count_swap) %>% 
  left_join(count_refined) %>%
  select(
    city_match,
    city_swap,
    city_refine,
    swap_count,
    refine_count
  ) %>% 
  mutate(diff_count = refine_count - swap_count) %>%
  mutate(refine_dist = stringdist(city_swap, city_refine)) %>%
  distinct() %>%
  arrange(city_refine) %>% 
  print_all()
```

We can finally manually correct the last of these values.

```{r refine_fix}
wa_refined$city_refine <- wa_refined$city_refine %>% 
  str_replace("^FOREST LAKE$", "LAKE FOREST PARK") %>% 
  str_replace("^REARDAN$", "ARDEN") %>% 
  str_replace("^CLEARLAKE$", "CLEAR LAKE") %>% 
  str_replace("^STEILCOOM$", "STEILACOOM") %>% 
  str_replace("^SOUTH ALASKA$", "KAHLOTUS") %>% 
  str_replace("^TULWILLA$", "TUKWILA") %>% 
  str_replace("^SEATTLE WEST$", "SEATTLE") %>% 
  str_replace("^MCCHAORD AFB$", "MCCHORD AFB") %>% 
  str_replace("^ORIENT$", "RENTON") %>% 
  str_replace("^TUMWATERS$", "TUMWATER") %>% 
  str_replace("^CARLTON$", "LA CONNER") %>% 
  str_replace("^CARLTON$", "LA CONNER") %>% 
  str_replace("^COSMOPOLIS$", "MOCLIPS") %>% 
  str_replace("^FERNDALE$", "FREELAND") %>% 
  str_replace("^LEAVENWORTH$", "LEAVENWORTH") %>% 
  str_replace("^MOUNTLAKE TERRACE$", "MOUNT LAKE TERRACE") %>% 
  str_replace("^MTLAKE TERRACE$", "MOUNT LAKE TERRACE") %>% 
  str_replace("^NORDLAND$", "RONALD") %>% 
  str_replace("^ORIENT$", "RENTON") %>% 
  str_replace("^RAYMOND$", "NORMANDY") %>% 
  str_replace("^SPOKANE VALLEY$", "SPOKANE") %>% 
  na_if("INTERNET COMPANY")

refine_table <- wa_refined %>% 
  select(id, city_refine)
```

#### Merge Refined City

Then, we match these refined values to the original data. Use the refined value where possible,
otherwise use the swapped city value (which is the prepared value or real value).

```{r join_refine}
wa <- wa %>% 
  left_join(refine_table, by = "id") %>% 
  mutate(city_clean = coalesce(city_refine, city_swap))
```

Each step of the cleaning process reduces the number of distinct city values.

```{r city_steps_distinct, collapse=TRUE}
n_distinct(wa$recipient_city)
n_distinct(wa$city_prep)
n_distinct(wa$city_swap)
n_distinct(wa$city_clean)
sum(wa$recipient_city != wa$city_clean, na.rm = TRUE)
sample(setdiff(wa$recipient_city, wa$city_clean), 25)
```

## Conclude

1. There are `r nrow(wa)` records in the database
1. There are `r sum(wa$dupe_flag)` records with duplicate filer, recipient, date, _and_ amount
(flagged with `dupe_flag`)
1. The ranges for dates and amounts are reasonable
1. Consistency in strings has been fixed with `city_prep()` and the `stringr` package
1. The five-digit `zip_clean` variable has been created with `zipcode::clean.zipcode()`
1. The `expenditure_year` variable has been created with `lubridate::year()`
1. There are `r sum(is.na(wa$recipient_name))` records with missing `recipient_name` values and 
`r sum(is.na(wa$expenditure_date))` records with missing `expenditure_date` values (both flagged
with the `na_flag`)

## Write

```{r write_csv}
wa %>% 
  select(
    -recipient_zip,
    -recipient_state,
    -recipient_city,
    -city_prep,
    -city_match,
    -match_dist,
    -city_swap,
    -city_refine
  ) %>% 
  write_csv(
    path = here("wa_expends", "data", "raw", "wa_expends_clean.csv"),
    na = ""
  )
```

