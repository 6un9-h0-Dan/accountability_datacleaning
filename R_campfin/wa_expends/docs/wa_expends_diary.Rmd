---
title: "Data Diary"
subtitle: "Washington Expenditures"
author: "Kiernan Nicholls"
date: "`r format(Sys.time())`"
output:
  github_document: 
    df_print: tibble
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
```

## Objectives

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called ZIP5
1. Create a YEAR field from the transaction date
1. For campaign donation data, make sure there is both a donor AND recipient

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

```{r p_load, message=FALSE, warning=FALSE, error=FALSE}
pacman::p_load(
  stringdist, # levenshtein value
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe opperators
  RSocrata, # read SODA APIs
  janitor, # dataframe clean
  zipcode, # clean & databse
  batman, # parse yes & no
  refinr, # cluster & merge
  rvest, # scrape website
  knitr, # knit documents
  here, # locate storage
  fs # search storage 
)
```

```{r fix_fun, echo=FALSE}
here <- here::here
"%out%" <- Negate("%in%")
print_all <- function(df) df %>% print(n = nrow(.)) 
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory
of the more general, language-agnostic `irworkshop/accountability_datacleaning` 
[GitHub repository](https://github.com/irworkshop/accountability_datacleaning).

The `R_campfin` project uses the 
[RStudio projects](https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects)
feature and should be run as such. The project also uses the dynamic 
[`here::here()`](https://github.com/jennybc/here_here) tool for
file paths relative to _your_ machine.

```{r where_here, collapse=TRUE}
# where was this document knit?
here::here()
```

## Data

This dataset comes courtesy of the State of 
[Washington Public Disclosure Commission](http://www.pdc.wa.gov), access through the [data.wa.gov](https://data.wa.gov) portal.

The resource is named `exenditures_by_candidates_and_political_committees` and covers the last 10
years of data, updates daily. Each records represents a single "Expenditure by a campaign or
committee."

### About

> This dataset contains expenditures made by Washington State Candidates and Political Committees
for the last 10 years as reported to the PDC on forms C3, C4, Schedule C and their electronic
filing equivalents.
> 
> In-kind contributions are included in this data set as they are considered as both a contribution
and expenditure. In-kind contributions are also included in the data set "Contributions to
Candidates and Political Committees."
> 
> For candidates, the number of years is determined by the year of the election, not necessarily the
year the expenditure was reported. For political committees, the number of years is determined by
the calendar year of the reporting period.
> 
> Candidates and political committees choosing to file under "mini reporting" are not included in
this dataset. See WAC 390-16-105 for information regarding eligibility.
> 
> This dataset is a best-effort by the PDC to provide a complete set of records as described
herewith and may contain incomplete or incorrect information. The PDC provides access to the
original reports for the purpose of record verification.
> 
> Descriptions attached to this dataset do not constitute legal definitions; please consult RCW
42.17A and WAC Title 390 for legal definitions and additional information regarding political
finance disclosure requirements.
> 
> CONDITION OF RELEASE: This publication constitutes a list of individuals prepared by the
Washington State Public Disclosure Commission and may not be used for commercial purposes. This
list is provided on the condition and with the understanding that the persons receiving it agree to
this statutorily imposed limitation on its use. See RCW 42.56.070(9) and AGO 1975 No. 15.

### Variables

The [Data.WA API page](https://dev.socrata.com/foundry/data.wa.gov/ukxb-bc7h) provides definitions
for the variables provided in this dataset.

`id`:

> PDC internal identifier that corresponds to a single expenditure record. When combined with the
origin value, this number uniquely identifies a single row.

`report_number`:

> PDC identifier used for tracking the individual form C4 . Multiple expenditures will have the
same report number when they were reported to the PDC at the same time. The report number is unique
to the report it represents. When a report is amended, a new report number is assigned that
supersedes the original version and the original report records are not included in this dataset.

`origin`:

> This field shows from which filed report-type the data originates. A/LE50 refers to non-itemized
expenditures of $50 and less per expenditure. A/GT50 refers to itemized expenditures greater than
$50 per expenditure. A/LE50 and A/GT50 are both reported on schedule A of form C4
>
> To view the different report types and forms browse to:https://www.pdc.wa.gov/learn/forms

`filer_id`:

> The unique id assigned to a candidate or political committee. The filer id is consistent across
election years with the exception that an individual running for a second office in the same
election year will receive a second filer id. There is no correlation between the two filer ids.
For a candidate and single-election-year committee such as a ballot committee, the combination of
filerid and electionyear uniquely identifies a campaign.

`type`:

> Indicates if this record is for a candidate or a political committee. In the case of a political
committee, it may be either a continuing political committee, party committee or single election
year committee.

`filer_name`:

> The candidate or committee name as reported on the form C1 candidate or committee registration
form. The name will be consistent across all records for the same filer id and election year but
may differ across years due to candidates or committees changing their name.

`id`:

> This field represents the first name, as reported by the filer. This field may appear blank if
the name is not reported or if a filing entity has a single name, such as a PAC or other political
committee. Note that this data appears as represented by the filer and may not be consistent from
one reporting period to another.

`last_name`:

> This field represents the last name, as reported by the filer. The field may also contain the
full name of a filing entity that is registered under one name, such as a PAC or other filing
committee. Note that this data appears as represented by the filer and may not be consistent from
one reporting period to another.

`office`:

> The office sought by the candidate. Does not apply to political committees.

`legislative_district`:

> The Washington State legislative district. This field only applies to candidates where the office
is "state senator" or "state representative."

`position`:

> The position associated with an office. This field typically applies to judicial and local office
that have multiple positions or seats. This field does not apply to political committees.

`party`:

> The political party as declared by the candidate or committee on their form C1 registration.
Contains only "Major parties" as recognized by Washington State law.

`ballot_number`:

> If the committee is a Statewide Ballot Initiative Committee a ballot number will appear once a
ballot number is assigned by the Secretary of State. Local Ballot Initiatives will not have a
ballot number. This field will contain a number only if the Secretary of State issues a number.

`for_or_against`:

> Ballot initiative committees are formed to either support or oppose an initiative. This field
represents whether a committee “Supports” or “Opposes” a ballot initiative.

`jurisdiction_*`:

> The political jurisdiction associated with the office of a candidate.

> The county associated with the jurisdiction of a candidate. Multi-county jurisdictions as
reported as the primary county. This field will be empty for political committees and when a
candidate jurisdiction is statewide.

> The type of jurisdiction this office is: Statewide, Local, etc.

`election_year`:

> The election year in the case of candidates and single election committees. The reporting year in
the case of continuing political committees.

`amount`:

> The amount of the expenditure or in-kind contribution. In-kind contributions are both a
contribution and an expenditure and represented in both the contributions and expenditures data.

`itemized_or_non_itemized`:

> A record for an itemized expenditure represents a single expenditure. A record for a non-itemized
expenditure represents one or more expenditures where the individual expenditures are less than the
limit for itemized reporting. In this case the record is the aggregate total for the reporting
period.

`expenditure_date`:

> The date that the expenditure was made or the in-kind contribution was received. See the metadata
for the origin and amount field regarding in-kind contributions.

`code`:

> The type of expenditure. The values displayed are human readable equivalents of the type codes reported on the form C4 schedule A. Please refer to the form for a listing of all codes. Itemized expenditures are generally required to have either a code or a description but may be required to have both. Non-itemized expenditures do not have a description. 

`recipient_name`:

> The name of the individual or vendor paid as reported. The names appearing here have not been normalized and the same entity may be represented by different names in the dataset. Non-itemized expenditures of $50 or less will have a recepient_name of EXPENSES OF $50 OR LESS and origin of A/LE50, and all address fields will be empty.

`recipient_*`:

> The street address of the individual or vendor paid as reported.

> The city of the individual or vendor paid as reported.

> The state of the individual or vendor paid as reported.

> The zip code of the individual or vendor paid as reported.

`url`:

> A link to a PDF version of the original report as it was filed to the PDC.

`recipient_location`:

> The geocoded location of the individual or vendor paid as reported. The quality of the geocoded
location is dependent on how many of the address fields are available and is calculated using a
third-party service. The PDC has not verified the results of the geocoding. Please refer to the
recipient_name field for more information regarding address fields.

## Read

> The [Socrata Open Data API (SODA)](http://dev.socrata.com/) provides programmatic access to this
dataset including the ability to filter, query, and aggregate data. For more more information, view
the [API docs for this dataset](https://dev.socrata.com/foundry/data.wa.gov/ukxb-bc7h) or visit our
[developer portal](http://dev.socrata.com/)

If an _recent_ version of the file doesn't exist locally, the `RSocrata::read.socrate()` function
can read the SODA dataset directly from the API into R.

```{r read_data}
wa_filename <- here(
  "wa_expends", "data", "raw", 
  "exenditures_by_candidates_and_political_committees.csv"
)  
if (file.exists(wa_filename) & as_date(file.mtime(wa_filename)) == today()) {
  wa <- read_csv(
    file = wa_filename,
    col_types = cols(.default = col_character())
  )
  read_from_soda = FALSE
} else {
  wa <- as_tibble(read.socrata("https://data.wa.gov/resource/ukxb-bc7h.json"))
  read_from_soda = TRUE
}
wa$amount <- parse_number(wa$amount)
wa$election_year <- parse_number(wa$election_year)
wa$expenditure_date <- as_date(wa$expenditure_date)
```

If the file had to be downloaded from the SODA API, save a copy of the raw data locally. Each
`recipient_location.coordinates` value is a list type, so they will have to be converted to
character vectors before being saved as a flat text file.

```{r write_raw}
dir_create(here("wa_expends", "data", "raw"))
if (read_from_soda) {
  wa %>% 
    mutate(recipient_location.coordinates = as.character(recipient_location.coordinates)) %>% 
    write_csv(
      path = wa_filename,
      na = ""
    )
}
```

Before working with the data in R, some binary character type variables will be converted to
logical variables. The coordinates character string will also be separated and converted to numeric
latitude and longitude variables.s

```{r parse_vars}
wa <- wa %>% 
  separate(
    col = recipient_location.coordinates,
    into = c("recipient_longitude", "recipient_latitude"),
    sep = ",\\s",
    remove = TRUE
  ) %>% 
  mutate(
    recipient_longitude = as.double(str_remove(recipient_longitude, "c\\(")),
    recipient_latitude = as.double(str_remove(recipient_latitude, "\\)")),
    expenditure_itemized = itemized_or_non_itemized == "Itemized",
    filer_supports = for_or_against == "For",
  ) %>% 
  select(
    -itemized_or_non_itemized,
    -for_or_against
  )
```

## Explore

There are `r nrow(wa)` records of `r length(wa)` variables in the full database.

```{r glimpse}
sample_frac(wa)
glimpse(sample_frac(wa))
```

### Distinct

The variables range in their degree of distinctness.

The `id` is `r scales::percent(n_distinct(wa$id)/nrow(wa))` distinct and can be used to
identify a unique transaction.

```{r n_distinct}
wa %>% 
  map(n_distinct) %>% 
  unlist() %>% 
  enframe(name = "variable", value = "n_distinct") %>% 
  mutate(prop_distinct = round(n_distinct / nrow(wa), 4)) %>%
  print(n = length(wa))
```

The `*_id` variables have as many distinct values as the length of their respective tables.

```{r tabyls_function, echo=FALSE}
print_tabyl <- function(data, ...) {
  as_tibble(arrange(tabyl(data, ...), desc(n)))
}
```

```{r tabyls, echo=FALSE}
wa %>% print_tabyl(origin)
wa %>% print_tabyl(type)
wa %>% print_tabyl(office)
wa %>% print_tabyl(position)
wa %>% print_tabyl(party)
wa %>% print_tabyl(jurisdiction_type)
wa %>% print_tabyl(election_year)
wa %>% print_tabyl(expenditure_itemized)
wa %>% print_tabyl(legislative_district)
wa %>% print_tabyl(code)
wa %>% print_tabyl(filer_supports)
```

```{r plot_origin_bar, echo=FALSE}
ggplot(wa) + geom_bar(aes(origin))
```

```{r plot_type_bar, echo=FALSE}
ggplot(wa) + geom_bar(aes(type))
```

```{r plot_party_bar, echo=FALSE}
ggplot(wa) + geom_bar(aes(party)) + coord_flip()
```

```{r plot_jurisdiction_bar, echo=FALSE}
ggplot(wa) + geom_bar(aes(jurisdiction_type))
```

```{r plot_election_year_bar, echo=FALSE}
ggplot(wa) + geom_bar(aes(election_year))
```

```{r plot_itemized_bar, echo=FALSE}
ggplot(wa) + geom_bar(aes(expenditure_itemized))
```

```{r plot_code_bar, echo=FALSE}
ggplot(wa %>% filter(!is.na(code))) + geom_bar(aes(code)) + coord_flip()
```

```{r plot_supports_bar, echo=FALSE}
ggplot(wa %>% filter(!is.na(filer_supports))) + geom_bar(aes(filer_supports))
```

### Missing

The variables also vary in their degree of values that are `NA` (missing).

```{r count_na}
wa %>% 
  map(function(var) sum(is.na(var))) %>% 
  unlist() %>% 
  enframe(name = "variable", value = "n_na") %>% 
  mutate(prop_na = n_na / nrow(wa)) %>% 
  print(n = length(wa))
```

We will flag any records with missing values in the key variables used to identify an expenditure.

```{r na_flag}
sum(is.na(wa$filer_name))
sum(is.na(wa$recipient_name))
sum(is.na(wa$amount))
sum(is.na(wa$expenditure_date))

wa <- wa %>% 
  mutate(
    na_flag = is.na(expenditure_date) | is.na(recipient_name)
  )

wa %>% 
  filter(na_flag) %>%
  sample_frac() %>% 
  select(
    na_flag,
    id, 
    report_number,
    filer_name,
    recipient_name,
    amount,
    expenditure_date
    )
```

### Ranges

The range of continuous variables will need to be checked for data integrity. There are only two
quasi-continuous variables, the `amount` and `expenditure_date`

#### Transaction Amounts

The middle range for `amount` seems reasonable enough.
`r scales::percent(mean(wa$amount < 0))` percent of `amount` values are less than zero. 

```{r amount_range}
summary(wa$amount)
tabyl(wa$amount > 0)
```

```{r plot_amt_nonlog, collapse=TRUE}
ggplot(wa, aes(amount)) + 
  geom_histogram() + 
  scale_y_log10() +
  scale_x_continuous(labels = scales::dollar) +
  geom_hline(yintercept = 10)
```

Below are the smallest and largest expenditures.

```{r glimpse_min_max}
glimpse(wa %>% filter(amount == min(amount, na.rm = T)))
glimpse(wa %>% filter(amount == max(amount, na.rm = T)))
```

We can view the link provided in the `url` variable to see the smallest expenditure is a correction
to an expenditure to Costco previously reported as \$8,929,810 that should have been \$6,429,810.
Interestingly, this same report shows a _contribution_ from the same Costco for the exact same
amount with the exact same correction. There is no description for the correction.

Using the `url` from the maximum report, the \$5,000,000 expenditure has "contribution" listed in
the "Purpose of Expense" box with nothing put in the spot for "Code" meant to identify the record
as a contribution or expenditure.

These two sample reports can be found as PDF files in the `data/` directory.

### Transaction Dates

There are a number of records with incorrect `expenditure_date` variables. There are no records
with expenditures made in the future, but there are a number of suspiciously old expenditures.

```{r date_future}
max(wa$expenditure_date, na.rm = TRUE)
sum(wa$expenditure_date > today(), na.rm = T)
```

PDC claims that the dataset covers the last 10 years of data, but there are thousands of records
older than that, with one from `r year(min(wa$expenditure_date, na.rm = TRUE))`. The report
containing that expenditure was filed in 2010 and can be found as PDF in the `data/` directory.
That one report is the only one with an expenditure date before 2000, the rest appear to be
correct dates simply outside the expected time span.

```{r date_past}
min(wa$expenditure_date, na.rm = TRUE)
sum(year(wa$expenditure_date) < 2007, na.rm = T)
```

```{r plot_exp_year, echo=FALSE}
wa %>% 
  count(year = year(expenditure_date)) %>% 
  ggplot(aes(year, n)) +
  geom_col() +
  coord_cartesian(xlim = c(2000, 2020)) +
  geom_vline(xintercept = 2008)
```

To better track expenditures in the TAP database, we will create a `expenditure_year` variable from
the previously parsed `expenditure_date` using `lubridate::year()`.

```{r add_year}
wa <- wa %>% 
  mutate(expenditure_year = year(expenditure_date))
```

## Plots

```{r plot_exp_party, echo=FALSE}
wa %>%
  filter(party %in% c("DEMOCRAT", "REPUBLICAN", NA)) %>% 
  group_by(party, code) %>% 
  summarise(mean = mean(amount)) %>%
  arrange(code) %>% 
  ggplot(aes(code, mean)) +
  geom_col(aes(fill = party)) +
  facet_wrap(~party) +
  coord_flip() +
  scale_y_continuous(labels = scales::dollar) +
  theme(legend.position = "none") +
  labs(
    title = "Washington State Campaign Expenditures",
    subtitle = "NA for Non-Candidate Campaigns",
    caption = "Source: data.wa.gov/d/tijg-9zyp",
    y = "Mean Expenditure",
    x = "Expenditure Type"
  )
```

## Clean

### Address

The `recipient_address` variable will be minimally cleaned by removing punctuation and fixing
white-space.

```{r}
wa <- wa %>% 
  mutate(
    address_clean = recipient_address %>% 
      str_to_upper() %>% 
      # remove punct and numbers
      str_replace("-", " ") %>% 
      str_remove_all("[:punct:]") %>% 
      str_trim() %>% 
      str_squish() %>% 
      na_if("") %>% 
      na_if("NA")
  )
```

### Zipcode

We can clean the `recipient_zip` variable using the `zipcodes::clean.zipcodes()` function, which
strips the ZIP+4 digits and adds leading zeroes to three or four digit strings. We will also make
some common invalid zips `NA`.

```{r zipcode_data, echo=FALSE}
data("zipcode")
zipcode <- zipcode %>% 
  as_tibble() %>% 
  select(city, state, zip)

zipcode$city <- zipcode$city %>%
  str_to_upper() %>% 
  str_replace_all("-", " ") %>% 
  str_remove_all("[:punct:]") %>% 
  str_replace("(^|\\b)N(\\b|$)",  "NORTH") %>%
  str_replace("(^|\\b)NO(\\b|$)", "NORTH") %>%
  str_replace("(^|\\b)S(\\b|$)",  "SOUTH") %>%
  str_replace("(^|\\b)SO(\\b|$)", "SOUTH") %>%
  str_replace("(^|\\b)E(\\b|$)",  "EAST") %>%
  str_replace("(^|\\b)W(\\b|$)",  "WEST") %>%
  str_replace("(^|\\b)MT(\\b|$)", "MOUNT") %>%
  str_replace("(^|\\b)ST(\\b|$)", "SAINT") %>%
  str_replace("(^|\\b)PT(\\b|$)", "PORT") %>%
  str_replace("(^|\\b)FT(\\b|$)", "FORT") %>%
  str_replace("(^|\\b)PK(\\b|$)", "PARK") %>%
  str_replace("CAMANO", "CAMANO ISLAND") %>% 
  str_trim() %>% 
  str_squish()
```

```{r clean_zipcodes}
wa <- wa %>% 
  mutate(zip_clean = recipient_zip %>% 
           clean.zipcodes() %>% 
           na_if("00000") %>% 
           na_if("11111") %>% 
           na_if("99999")
  )

wa$zip_clean[which(nchar(wa$zip_clean) != 5)] <- NA
```

### State

Using comprehensive list of state abbreviations in the Zipcodes database, we can isolate invalid
`recipient_state` values and manually correct them.

```{r valid_state, collapse=TRUE}
valid_state <- c(unique(zipcode$state), "AB", "BC", "MB", "NB", "NL", "NS", "ON", "PE", "QC", "SK")
length(valid_state)
setdiff(valid_state, state.abb)
```

```{r}
setdiff(wa$recipient_state, valid_state)
wa %>% 
  filter(recipient_state %out% valid_state) %>% 
  filter(!is.na(recipient_state)) %>% 
  select(
    id,
    recipient_address,
    recipient_city,
    recipient_state,
    recipient_zip
  ) %>% 
  print_all()
```

If the `recipient_state` abbreviation is invalid, use the `recipient_city` and `recipient_zip`
values for that record to manually correct the abbreviation where possible. If it can't be manually
corrected, make the value `NA`.

```{r}
wa$state_clean <- wa$recipient_state %>% 
  str_replace("QA", "WA") %>% # add match
  str_replace("SW", "WA") %>% # add match 
  str_replace("TE", "TX") %>% # add match
  str_replace("CN", "AB") %>% # calgary
  str_remove("[:punct:]") %>% 
  na_if("") %>% 
  na_if("RE") %>% # requested
  na_if("98") %>% # WA zip
  na_if("99") %>% # WA zip
  na_if("SH") %>% # hong kong
  na_if("FR") %>% # france
  na_if("OT") %>% # overseas
  na_if("HR") %>% # hungary
  na_if("UK") %>% # united kingdom
  na_if("IR") %>% # ireland
  na_if("IS")     # israel
```

### City

The first step in cleaning city names is to reduce inconsistencies. The custom `city_prep()`
function found in the `R/` sub-directory of this root project performs the bulk of our preparation.
In short, the function (1) removes punctuation, numbers, and state abbreviations, (2) expands
directional and geographic abbreviations, and (3) catches common `NA` strings.

```{r prep_city}
source(here("R", "prep_city.R"))
wa <- wa %>% 
  mutate(
    city_prep = prep_city(
      cities = recipient_city,
      na = read_lines(here("R", "na_city.csv")),
      abbs = c("WA", "OR", "ID", "DC", "BC")
    )
  )
```

The second step will be to compare the new `city_prep` value to the _actual_ city value for that
record's `zip_clean` value. If the `city_prep` is very similar to the expected city name for that
ZIP code, we can make that change.

```{r match_dist}
wa <- wa %>%
  left_join(zipcode, by = c("state_clean" = "state", "zip_clean" = "zip")) %>%
  rename(city_match = city) %>%
  mutate(
    match_dist  = stringdist(city_prep, city_match),
    city_swap = if_else(match_dist == 1, city_match, city_prep)
  )
```

Now that we've prepared out city values and made the most obvious changes, we can use the
OpenRefine algorithms to cluster similar values and merge them together. This can be done using the
`refinr::key_collision_merge()` and `refinr::n_gram_merge()` functions on our prepared and swapped
city data.

We will create a new table with these refined values.

```{r view_refine}
wa_refined <- wa %>%
  filter(state_clean == "WA") %>% 
  filter(match_dist != 1) %>% 
  mutate(
    city_refine = city_swap %>% 
      key_collision_merge(dict = unique(zipcode$city)) %>% 
      n_gram_merge(numgram = 1),
    refined = (city_swap != city_refine)
  ) %>% 
  filter(refined) %>% 
  select(
    id,
    state_clean,
    zip_clean,
    recipient_city,
    city_prep,
    city_match,
    match_dist,
    city_swap,
    city_refine,
  ) %>% 
  rename(
    state = state_clean,
    zip = zip_clean,
    city_raw = recipient_city
  )
```

```{r most_refined}
wa_refined %>% 
  count(city_swap, city_refine) %>% 
  arrange(desc(n))
```

The key to the refine algorithms is clustering rare values with their more common similar values.
We can count how often the original value appears and compare it to the frequency of the refined
value.

```{r count_refined}
refined_values <- unique(wa_refined$city_refine)
count_refined <- tibble(
  city_refine = refined_values, 
  refine_count = NA
)

for (i in seq_along(refined_values)) {
  count_refined$refine_count[i] <- sum(str_detect(wa$city_swap, refined_values[i]), na.rm = TRUE)
}

swap_values <- unique(wa_refined$city_swap)
count_swap <- tibble(
  city_swap = swap_values, 
  swap_count = NA
)

for (i in seq_along(swap_values)) {
  count_swap$swap_count[i] <- sum(str_detect(wa$city_swap, swap_values[i]), na.rm = TRUE)
}
```

```{r distinct_refined}
wa_refined %>% 
  arrange(city_refine) %>%
  left_join(count_swap) %>% 
  left_join(count_refined) %>% 
  select(
    city_swap, 
    swap_count, 
    city_refine, 
    refine_count
  ) %>% 
  distinct() %>% 
  print_all()
```

There are only a few distinct refined values that do not appear in our list of valid cities. These
are the values that need to be checked manually checked.

```{r}
wa_refined %>% 
  filter(city_refine %out% zipcode$city) %>% 
  select(-id) %>% 
  distinct()
```

## Write

```{r write_csv}
wa %>% 
  select(
    -recipient_zip,
    -recipient_state
  ) %>% 
  write_csv(
    path = here("wa_expends", "data", "raw", "wa_expends_clean.csv"),
    na = ""
  )
```

