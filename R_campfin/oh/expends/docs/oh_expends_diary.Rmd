---
title: "Ohio Expenditures"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_current_gh("kiernann/campfin")
pacman::p_load(
  stringdist, # levenshtein value
  RSelenium, # remote browser
  tidyverse, # data manipulation
  lubridate, # datetime strings
  tidytext, # text analysis
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here, collapse=TRUE}
# where dfs this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

Data is obtained from the [Ohio Secretary of State Campaign Finance site][03].

> Search, view and download campaign finance data filed with the Secretary of State's office. Under
Ohio Revised Code 3517.106(E), information will be provided within five days of an entity filing
data with the Secretary of State's office.

The OH SOS provides an FTP (File Transfer Page) option for obtaining bulk data.

> Welcome to the Ohio Secretary of State's Campaign Finance File Transfer Page. This page was
developed to allow users to obtain large sets of data faster than the normal query process. At this
page you can download files of pre-queried data, such as all candidate contributions for a
particular year or a list of all active political action committees registered with the Secretary
of State. In addition, campaign finance data filed prior to 2000 is available only on this site.
These files contain all relevant and frequently requested information. If you are looking for
smaller or very specific sets of data please use the regular Campaign Finance queries listed on the
tabs above.
> 
> The data is in a "comma delimited" format that loads easily into Microsoft Excel or Access as
well as many other spreadsheet or database programs. Many of the available files contain a
significant quantity of data records. A spreadsheet program, such as Microsoft Excel, may not allow
all of the data in a file to be loaded because of a limit on the number of available rows. For this
reason, it is advised that a database application be utilized to load and work with the data
available at this site. For more information please contact the Campaign Finance unit at (614)
466-3111 or CFINANCE@SOS.STATE.OH.US

[03]: https://www.sos.state.oh.us/campaign-finance/search/

## Import

### Download

To download the annual files, we need to manually click on the download link for each.

> On the FTP page, please decide which information you would like to download. Click "Download
File" on the right hand side. The system will then proceed to download the file into Microsoft
Excel or provide you will an opportunity to download the file to the location on your computer (the
settings on your computer will dictate this). You may see a series of dialog boxes on your screen
asking you if you want to run or save the zipped .exe file. Follow the dialog boxes for whichever
you chose telling the computer where you want the files saved. The end result will be a .csv file
that you can open in Microsoft Excel or some other database application.

We can automate this process with the RSelenium package.

```{r raw_dir}
raw_dir <- here("oh", "expends", "data", "raw")
dir_create(raw_dir)
```

```{r remote_download, eval=FALSE}
# open the driver with auto download options
remote_driver <- rsDriver(
  port = 4444L,
  browser = "firefox",
  extraCapabilities = makeFirefoxProfile(
    list(
      browser.download.dir = raw_dir,
      browser.download.folderList = 2L,
      browser.helperApps.neverAsk.saveToDisk = "text/CSV"
    )
  )
)

# navigate to the OH FTP site for candidates
remote_browser <- remote_driver$client
can_url <- "https://www6.sos.state.oh.us/ords/f?p=CFDISCLOSURE:73:16499944485586:CAN:NO:RP:P73_TYPE:CAN:"
remote_browser$navigate(can_url)

# create the CSS selectors for the expends links
childs <- seq(from = 5, to = 43, by = 2)
css_selectors <- glue("tr.highlight-row:nth-child({childs}) > td:nth-child(4) > a:nth-child(1)")

# click on every CSS selector
for (selector in css_selectors) {
  remote_browser$findElement("css", selector)$clickElement()
}

# navigate to the OH FTP site for committees
pac_url <- "https://www6.sos.state.oh.us/ords/f?p=CFDISCLOSURE:73:13908331107877:PAC:NO:RP:P73_TYPE:PAC:"
remote_browser$navigate(pac_url)

# click on every CSS selector
for (selector in css_selectors) {
  remote_browser$findElement("css", selector)$clickElement()
}

# close the browser and driver
remote_browser$close()
remote_driver$server$stop()
```

### Read

We can combine each annual file into a single data frame by using `purrr::map()` to read each file
with `readr::read_csv()` into a single list, then bind each list element with `dplyr::bind_rows()`.

```{r read_raw}
oh <- 
  dir_ls(
    path = raw_dir, 
    glob = "*EXP*.CSV$"
  ) %>% 
  map(
    read_csv,
    col_types = cols(
      .default = col_character(),
      RPT_YEAR = col_integer(),
      EXPEND_DATE = col_date("%m/%d/%Y"),
      AMOUNT = col_number(),
      EVENT_DATE = col_date("%m/%d/%Y"),
      INKIND = col_logical(),
      DISTRICT = col_integer()
    )
  ) %>% 
  bind_rows(.id = "file") %>%
  mutate(file = basename(file)) %>%
  clean_names() %>% 
  rename(city_raw = city)
```

## Explore

```{r glimpse}
head(oh)
tail(oh)
glimpse(sample_frac(oh))
```

### Missing

```{r count_na}
glimpse_fun(oh, count_na)
```

There are `r count_na(oh$com_name)` missing values for the `com_name` variable, used to identify 
the giving party to the expenditure. The payee is identified by either `last_name` for individuals
or `non_individual` for, well, non individuals. There are some records without wither payee name, 
which we will now flag with `na_flag`. We will also flag any record missing an `amount` value.
However, there `r percent(mean(is.na(oh$expend_date)))` of records are missing an `expend_date`,
too usefully many to flag.

```{r flag_na}
oh <- mutate(oh, na_flag = (is.na(last_name) & is.na(non_individual)) | is.na(amount))
sum(oh$na_flag)
```

### Duplicates

There are many duplicated records, `r percent((nrow(oh)-nrow(distinct(oh)))/nrow(oh))` of the 
entire database.

```{r distinct_rows}
nrow(oh) - nrow(distinct(oh))
```

### Categorical

```{r n_distinct}
glimpse_fun(oh, n_distinct)
```

```{r words_bar, echo=FALSE}
oh %>% 
  unnest_tokens(word, purpose) %>% 
  anti_join(stop_words) %>% 
  count(word, sort = TRUE) %>% 
  filter(!is.na(word)) %>% 
  head(25) %>% 
  ggplot(aes(reorder(word, n), n)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Ohio Expenditure Purpose Words",
    x = "Word",
    y = "Frequency",
    caption = "Source: OH SOS"
  )
```

### Continuous

#### Amounts

```{r}
summary(oh$amount)
sum(oh$amount < 0, na.rm = TRUE)
```

```{r}
oh %>% 
  ggplot(aes(amount)) +
  geom_histogram() +
  scale_x_continuous(
    trans = "log10", 
    labels = dollar,
    breaks = c(1, 10, 100, 1000, 10000, 100000, 1000000)
  ) +
  labs(
    title = "Ohio Expenditures Amount Distribution",
    x = "Amount",
    y = "Count",
    caption = "Source: OH SOS"
  )
```

```{r amount_box_party, echo=FALSE}
oh %>% 
  filter(party %in% c(
    "REPUBLICAN", 
    "DEMOCRAT", 
    "NON-PARTISAN", 
    "INDEPENDENT"
  )) %>% 
  ggplot(
    mapping = aes(
      y = amount,
      x = reorder(
        x = party, 
        X = amount, 
        FUN = median, 
        na.rm = TRUE
      )
    )
  ) +
  geom_boxplot(
    mapping = aes(fill = party),
    varwidth = TRUE,
    outlier.alpha = 0.01
  ) +
  scale_y_continuous(
    breaks = c(1 %o% 10^(0:6)),
    labels = dollar,
    trans = "log10"
  ) +
  scale_fill_manual(
    guide = FALSE,
    values = c(
      "steelblue",
      "grey10",
      "mediumpurple",
      "red2"
    )
  ) +
  labs(
    title = "Ohio Expenditures Amount Range",
    x = "Party",
    y = "Amount",
    caption = "Source: OH SOS"
  )
```

#### Dates

```{r add_year}
oh <- mutate(oh, expend_year = year(expend_date))
min_year <- min(as.double(str_extract(dir_ls(raw_dir) , "\\d{4}")))
```

```{r date_range, collapse=TRUE}
min(oh$expend_date, na.rm = TRUE)
sum(oh$expend_year < min_year, na.rm = TRUE)
max(oh$expend_date, na.rm = TRUE)
sum(oh$expend_date > today(), na.rm = TRUE)
```

```{r flag_dates}
oh <- mutate(oh, date_flag = expend_year < min_year | expend_date > today())
sum(oh$date_flag, na.rm = TRUE)
```

```{r clean_dates}
oh <- oh %>% 
  mutate(
    date_clean = as_date(ifelse(date_flag, NA, expend_date)),
    year_clean = year(date_clean)
  )
```

```{r report_year_bar, echo=FALSE}
oh %>% 
  count(rpt_year) %>% 
  mutate(
    p = n/sum(n),
    election = is_even(rpt_year)
  ) %>% 
  ggplot(aes(rpt_year, p)) +
  geom_col(aes(fill = election)) +
  scale_y_continuous(labels = percent) +
  scale_fill_brewer(
    type = "qual", 
    palette = "Dark2",
    guide = FALSE
  ) +
  theme(legend.position = "bottom") +
  labs(
    title = "Ohio Expenditures Report Year",
    x = "Report Year",
    y = "Percent",
    fill = "Election Year",
    caption = "Source: OH SOS"
  )
```

```{r year_count_bar, echo=FALSE}
oh %>% 
  count(year_clean) %>% 
  mutate(
    p = n/sum(n),
    election = is_even(year_clean)
  ) %>% 
  ggplot(aes(year_clean, p)) +
  geom_col(aes(fill = election)) +
  scale_y_continuous(labels = percent) +
  scale_fill_brewer(
    type = "qual", 
    palette = "Dark2",
  ) +
  theme(legend.position = "bottom") +
  labs(
    title = "Ohio Expenditures Year Made",
    x = "Year Made",
    y = "Percent",
    fill = "Election Year",
    caption = "Source: OH SOS"
  )
```

```{r year_amount_bar, echo=FALSE}
oh %>% 
  group_by(year_clean) %>% 
  summarize(mean = mean(amount, na.rm = TRUE)) %>% 
  mutate(election = is_even(year_clean)) %>% 
  ggplot(aes(year_clean, mean)) +
  geom_col(aes(fill = election)) +
  scale_y_continuous(labels = dollar) +
  scale_fill_brewer(
    type = "qual", 
    palette = "Dark2",
  ) +
  theme(legend.position = "bottom") +
  labs(
    title = "Ohio Expenditures Mean Amount by Year",
    x = "Year Made",
    y = "Mean Amount",
    fill = "Election Year",
    caption = "Source: OH SOS"
  )
```

```{r month_amount_line, echo=FALSE}
oh %>% 
  mutate(
    month = month(date_clean),
    election = is_even(year_clean)
  ) %>% 
  group_by(month, election) %>% 
  summarize(mean = mean(amount, na.rm = TRUE)) %>% 
  drop_na() %>% 
  ggplot(aes(month, mean)) +
  geom_line(
    mapping = aes(color = election),
    size = 2
  ) +
  scale_y_continuous(labels = dollar) +
  scale_x_continuous(
    breaks = 1:12,
    labels = month.abb
  ) +
  scale_color_brewer(
    type = "qual", 
    palette = "Dark2",
  ) +
  theme(legend.position = "bottom") +
  labs(
    title = "Ohio Expenditures Mean Amount by Month",
    x = "Year Made",
    y = "Mean Amount",
    fill = "Election Year",
    caption = "Source: OH SOS"
  )
```

```{r month_total_line, echo=FALSE}
oh %>% 
  mutate(
    month = month(date_clean),
    election = is_even(year_clean)
  ) %>% 
  group_by(election, month) %>%
  summarize(mean = mean(amount, na.rm = TRUE)) %>% 
  arrange(election, month) %>% 
  mutate(total = cumsum(mean)) %>% 
  drop_na() %>% 
  ggplot(aes(month, total)) +
  geom_line(
    mapping = aes(color = election),
    size = 2
  ) +
  scale_y_continuous(labels = dollar) +
  scale_x_continuous(
    breaks = 1:12,
    labels = month.abb
  ) +
  scale_color_brewer(
    type = "qual", 
    palette = "Dark2",
  ) +
  theme(legend.position = "bottom") +
  labs(
    title = "Ohio Expenditures Total Amount over Year",
    x = "Year Made",
    y = "Mean Amount",
    fill = "Election Year",
    caption = "Source: OH SOS"
  )
```

## Wrangle

### Address

```{r normal_address}
oh <- oh %>% 
  mutate(
    address_norm = normal_address(
      address = address,
      add_abbs = usps,
      na_rep = TRUE
    )
  )
```

```{r view_address_change, echo=FALSE}
oh %>% 
  sample_n(10) %>% 
  select(
    address,
    address_norm
  )
```

### ZIP

```{r count_zip_pre, collapse=TRUE}
n_distinct(oh$zip)
prop_in(oh$zip, geo$zip, na.rm = TRUE)
length(setdiff(oh$zip, geo$zip))
```

```{r normal_zip}
oh <- oh %>% 
  mutate(
    zip_norm = normal_zip(
      zip = zip,
      na_rep = TRUE
    )
  )
```

```{r count_zip_post, collapse=TRUE}
n_distinct(oh$zip_norm)
prop_in(oh$zip_norm, geo$zip, na.rm = TRUE)
length(setdiff(oh$zip_norm, geo$zip))
```

### State

```{r count_state_pre, collapse=TRUE}
n_distinct(oh$state)
prop_in(oh$state, geo$state, na.rm = TRUE)
length(setdiff(oh$state, geo$state))
setdiff(oh$state, geo$state)
```

```{r normal_state}
oh <- oh %>% 
  mutate(
    state_norm = normal_state(
      state = state,
      abbreviate = FALSE,
      valid = geo$state
    )
  )
```

```{r count_state_post, collapse=TRUE}
n_distinct(oh$state_norm)
prop_in(oh$state_norm, geo$state, na.rm = TRUE)
length(setdiff(oh$state_norm, geo$state))
```

### City

```{r count_city_pre, collapse=TRUE}
n_distinct(oh$city_raw)
prop_in(oh$city_raw, geo$city, na.rm = TRUE)
length(setdiff(oh$city_raw, geo$city))
```

#### Normalize

```{r normal_city}
oh <- oh %>% 
  mutate(
    city_norm = normal_city(
      geo_abbs = usps_city,
      st_abbs = c("OH", "DC", "OHIO"),
      na = na_city,
      na_rep = TRUE,
      city = city_raw %>% 
        str_replace("^CIN$",   "CINCINNATI") %>% 
        str_replace("^COL$",   "COLUMBUS")   %>% 
        str_replace("^CLEVE$", "CLEVELAND")  %>% 
        str_replace("^CINTI$", "CINCINNATI") %>% 
        str_replace("^YO$",    "YOUNGSTOWN") %>% 
        str_replace("^COLS$",  "COLUMBUS")   %>% 
        str_replace("^CINCI$", "CINCINNATI") %>% 
        str_replace("^CLEV$",  "CLEVELAND")  %>% 
        str_replace("^CLE$",   "CLEVELAND")  %>% 
        str_replace("^LKWD$",  "LAKEWOOD")   %>% 
        str_replace("^CINT$",  "CINCINNATI") %>% 
        str_replace("^ATL$",   "ATLANTA")
    )
  )
```

```{r count_city_post_norm, collapse=TRUE}
n_distinct(oh$city_norm)
prop_in(oh$city_norm, geo$city, na.rm = TRUE)
length(setdiff(oh$city_norm, geo$city))
```

#### Swap

```{r swap_city}
oh <- oh %>% 
  left_join(
    y = geo,
    by = c(
      "state_norm" = "state",
      "zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_dist = stringdist(city_norm, city_match),
    city_swap = if_else(
      condition = (match_dist <= 2),
      true = city_match,
      false = city_norm
    )
  )
```

```{r count_city_post_swap, collapse=TRUE}
n_distinct(oh$city_swap)
prop_in(oh$city_swap, geo$city, na.rm = TRUE)
length(setdiff(oh$city_swap, geo$city))
summary(oh$match_dist)
```

#### Refine

```{r city_refine}
oh_refined <- oh %>%
  filter(
    state_norm == "OH",
    match_dist > 2,
  ) %>% 
  mutate(
    city_refine = city_swap %>% 
      key_collision_merge(dict = geo$city[geo$state == "OH"]) %>% 
      n_gram_merge(numgram = 1, bus_suffix = FALSE)
  ) %>% 
  filter(city_refine != city_swap)
```

```{r good_refine}
good_refined <- oh_refined %>% 
  inner_join(
    y = geo,
    by = c(
      "city_refine" = "city",
      "state_norm" = "state",
      "zip_norm" = "zip"
    )
  )
```

```{r join_refine}
oh <- oh %>%
  left_join(good_refined) %>% 
  mutate(city_clean = coalesce(city_refine, city_swap))
```

```{r count_city_post_refine, collapse=TRUE}
n_distinct(oh$city_clean)
prop_in(oh$city_clean, geo$city, na.rm = TRUE)
length(setdiff(oh$city_clean, geo$city))
```

#### Progress

```{r city_progress, collapse=TRUE}
n_distinct(oh$city_raw)
n_distinct(oh$city_norm)
n_distinct(oh$city_swap)
n_distinct(oh$city_clean)

prop_in(oh$city_raw, geo$city)
prop_in(oh$city_norm, geo$city)
prop_in(oh$city_swap, geo$city)
```

## Conclude

```{r conclude_dupe, echo=FALSE}
sum_dupe <- nrow(oh) - nrow(distinct(oh))
prop_dupe <- sum_dupe/nrow(oh)
```

1. There are `r nrow(oh)` records in the database.
1. There are `r sum_dupe` duplicate records, `r percent(prop_dupe)` of records. Not yet flagged.
1. The range and distribution of `amount` and `date` seem reasonable.
1. There are `r sum(oh$na_flag)` records missing either recipient or date.
1. Consistency in goegraphic data has been improved with `campfin::normal_*()`.
1. The 5-digit `zip_norm` variable has been created with `campfin::normal_zip(oh$zip)`.
1. The 4-digit `year_clean` variable has been created with `lubridate::year(oh$date_clean)`.

## Export

```{r proc_dir}
proc_dir <- here("oh", "expends", "data", "processed")
dir_create(proc_dir)
```

```{r write_clean}
oh %>% 
  select(
    -city_raw,
    -state,
    -zip,
    -expend_date,
    -expend_year,
    -city_norm,
    -city_match,
    -match_dist,
    -city_swap,
    -city_refine
  ) %>% 
  write_csv(
    na = "",
    path = glue("{proc_dir}/oh_expends_clean.csv")
  )
```

