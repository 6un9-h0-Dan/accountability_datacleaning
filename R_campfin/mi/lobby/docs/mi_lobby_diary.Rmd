---
title: "Michigan Lobbyists"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
fs::dir_create(here::here("mi", "lobby", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

Data is obtained from the [Michigan Secretary of State][sos]. The data is provided by NICUSA, Inc.,
which provides information technology services for the SOS. 

> Use this page to search for information concerning individuals and organizations registered under
the Michigan Lobby Registration Act, as well as expenditures disclosed by these registrants on
required financial reports. The record for each registrant will also include a listing of any
reported employees compensated by each registrant for lobbying, as well as employers who report the
registrant as an employee compensated for lobbying on behalf of the employer.
>
> You may download the entire list of Michigan registrants by clicking on the Spreadsheet Format
box and following the instructions provided.

The website certificates are out of date, so we can only obtain the file by using `curl` with the
`--insecure` option.

[sos]: https://www.michigan.gov/sos/

```{r raw_dir}
raw_dir <- here("mi", "lobby", "data", "raw")
dir_create(raw_dir)
```

```{r raw_curl}
lob_url <- "https://miboecfr.nicusa.com/cfr/dumpdata/aaa4NaO5g/mi_lobby.sh"
lob_path <- url2path(lob_url, raw_dir)
download.file(
  url = lob_url,
  destfile = lob_path,
  method = "curl",
  extra = "--insecure"
)
```

## Import

As described on the [data website][raw]:

> #### Other Notes:...
> The file is TAB delimited and NO quotes surround string text.
>
> The first record DOES contain the field names.
>
> The second record is a 'dummy' record used primarily to clue database programs like Access in as to
how to import the data, as well as some other useful information. You may want to delete this
record AND the record(s) at the end of the file containing counts once you have gotten any use from
them.
>
> When saving the mi_lobby.sh file, you may want to rename it with an extension of .txt, so that
certain database programs will import it correctly. The Bureau of Elections makes every effort to
provide accurate information to the public. However, any data taken from the database should be
verified against the actual report filed by the lobby. The information provided here is deemed
reliable but not guaranteed.

We can use this information to define the parameters of `readr::read_delim()`.

[raw]: https://miboecfr.nicusa.com/cgi-bin/cfr/lobby_srch_res.cgi

```{r raw_read}
milr <- read_delim(
  file = lob_path,
  delim = "\t",
  skip = 2,
  col_names = c(
    "id", "type", "last", "first", "mi", "sig", "addr", 
    "city", "state", "zip", "phone", "reg", "term"
  ),
  col_types = cols(
    .default = col_character(),
    type = col_factor(),
    reg = col_date_usa(),
    term = col_date_usa()
  )
)
```

## Explore

```{r raw_glimpse}
head(milr)
tail(milr)
glimpse(sample_frac(milr))
```

As we can see from `tail()`, the last two rows still need to be removed.

The `id` variable is unique to each lobbyist, so we can use it to remove the invalid rows.

```{r n_distinct}
col_stats(milr, n_distinct)
```

```{r raw_filter}
milr <- filter(milr, !is.na(id))
```

Now, there are no rows missing the key information needed to identify lobbyists.

```{r count_na}
col_stats(milr, count_na)
```

There are no duplicate rows in the database.

```{r duplicated}
sum(duplicated(milr))
```

The database contains both outside lobbyist and lobbying agents.

```{r plot_agent, echo=FALSE}
explore_plot(
  data = milr,
  var = type,
  title = "Michigan Lobbyist Types",
  subtitle = "A = Agent, L = Lobbyist"
)
```

`r percent(prop_na(milr$term))` of lobbyists in the database have a termination date, meaning only
`r percent(1-prop_na(milr$term))` of the records identify active lobbyists.

```{r term_na}
prop_na(milr$term)
```

We can add the registration year using `lubridate::year()` on the date column.

```{r year_add}
milr <- mutate(milr, year = year(reg))
```

```{r year_plot, echo=FALSE}
milr %>% 
  count(year) %>% 
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = RColorBrewer::brewer.pal(3, "Dark2")[3]) +
  labs(
    title = "Michigan Lobbyists Registered per Year",
    x = "Year Registered",
    y = "Lobbyists"
  )
```

## Wrangle

To improve the searchability and consistency of the database, we can perform some very basic and
confident text normalization.

### Phone

We can convert the phone numbers into a standard charatcer (i.e., non-numeric) format.

```{r phone_norm}
milr <- mutate(milr, phone_norm = normal_phone(phone))
```

```{r phone_view, echo=FALSE}
milr %>% 
  select(starts_with("phone")) %>% 
  distinct() %>% 
  sample_frac()
```

### Address

We can use `campfin::normal_address()` to improve the consistency in the `addr` variable.

```{r addr_norm}
milr <- mutate(milr, addr_norm = normal_address(addr, abbs = usps_street))
```

```{r addr_view, echo=FALSE}
milr %>% 
  select(starts_with("addr")) %>% 
  distinct() %>% 
  sample_frac()
```

### ZIP

```{r zip_norm}
milr <- mutate(milr, zip_norm = normal_zip(zip, na_rep = TRUE))
```

```{r zip_view, echo=FALSE}
milr %>% 
  select(starts_with("zip")) %>% 
  distinct() %>% 
  sample_frac()
```

```{r zip_progress}
progress_table(
  milr$zip,
  milr$zip_norm,
  compare = valid_zip
)
```

### State

The `state` variable does not need to be cleaned.

```{r state_prop}
prop_in(milr$state, valid_state)
```

### City

```{r city_norm}
milr <- mutate(milr, city_norm = normal_city(city, abbs = usps_city, na = invalid_city))
```

```{r city_swap}
milr <- milr %>% 
  rename(city_raw = city) %>% 
  left_join(
    y = zipcodes,
    by = c(
      "state" = "state",
      "zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_abb = is_abbrev(city_norm, city_match),
    match_dist = str_dist(city_norm, city_match),
    city_swap = if_else(
      condition = match_abb | match_dist == 1,
      true = city_match,
      false = city_norm
    )
  )
```

```{r city_filter}
out <- milr %>% 
  filter(city_swap %out% valid_city) %>% 
  count(city_swap, state, sort = TRUE) %>% 
  drop_na()
```

```{r city_check}
check_file <- here("mi", "lobby", "data", "api_check.csv")
if (file_exists(check_file)) {
  check <- read_csv(
    file = check_file
  )
} else {
  check <- pmap_dfr(
    .l = list(
      out$city_swap, 
      out$state
    ), 
    .f = check_city, 
    key = Sys.getenv("GEOCODE_KEY"), 
    guess = TRUE
  ) %>% 
    mutate(guess = coalesce(guess_city, guess_place)) %>% 
    select(-guess_city, -guess_place)
  write_csv(
    x = check,
    path = check_file
  )
}
```

```{r check_accept}
valid_locality <- check$guess[check$check_city_flag]
```

```{r check_compare}
valid_locality <- check %>% 
  filter(!check_city_flag) %>% 
  mutate(
    abb = is_abbrev(original_city, guess),
    dist = str_dist(original_city, guess)
  ) %>%
  filter(abb | dist <= 3) %>% 
  pull(guess) %>% 
  c(valid_locality)
```

```{r check_combine}
many_city <- c(valid_city, extra_city, valid_locality)
```

```{r city_progress, echo=FALSE}
progress <- progress_table(
  milr$city_raw,
  milr$city_norm,
  milr$city_swap,
  compare = many_city
) %>% mutate(stage = as_factor(stage))
```

```{r progress_print, echo=FALSE}
kable(progress, digits = 3)
```

## Export

```{r proc_dir}
proc_dir <- here("mi", "lobby", "data", "processed")
dir_create(proc_dir)
```

```{r proc_write}
write_csv(
  x = milr,
  path = glue("{proc_dir}/mi_lobby_reg.csv"),
  na = ""
)
```

