---
title: "Illinois Lobbyists Expenditures Data Diary"
author: "Yanqi Xu"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
if (!interactive()) {
  options(width = 99)
  set.seed(5)
}
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
doc_dir <- fs::dir_create(here::here("nj", "lobby", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give
journalists, policy professionals, activists, and the public at large a simple
way to search across huge volumes of public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each
dataset row as a transaction. For each transaction there should be (at least) 3
variables:

1. All **parties** to a transaction.
2. The **date** of the transaction.
3. The **amount** of money involved.

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for entirely duplicated records.
1. Check ranges of continuous variables.
1. Is there anything blank or missing?
1. Check for consistency issues.
1. Create a five-digit ZIP Code called `zip`.
1. Create a `year` field from the transaction date.
1. Make sure there is data on both parties to a transaction.

## Packages

The following packages are needed to collect, manipulate, visualize, analyze,
and communicate these results. The `pacman` package will facilitate their
installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This
package contains functions custom made to help facilitate the processing of
campaign finance data.

```{r load_packages, message=FALSE, warning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  tidyverse, # data manipulation
  lubridate, # datetime strings
  gluedown, # printing markdown
  magrittr, # pipe operators
  janitor, # clean data frames
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  rvest, # html scraping
  glue, # combine strings
  here, # relative paths
  httr, # http requests
  fs # local storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a
sub-directory of the more general, language-agnostic
[`irworkshop/accountability_datacleaning`][tap] GitHub repository.

The `R_campfin` project uses the [RStudio projects][rproj] feature and should be
run as such. The project also uses the dynamic `here::here()` tool for file
paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::here()
```

[tap]: https://github.com/irworkshop/accountability_datacleaning
[rproj]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects

## Data

Lobbying data is obtained from the Illinois Secretary of State via a public record request. The data is as current as of June 26, 2020. There're six relational tables which can be joined by IDs. 


1. `Agent.csv` for lobbyist names and addresses.
2. `BillSearch.csv` for lobbying activity on certain bills.
3. `Client.csv` for client names.
4. `Firm.csv` for firm names and addresses.
5. `IndexClient.csv` for agent, firm, client relationships.

[elec]: https://www.elec.state.nj.us/
[portal]: https://www3-elec.mwg.state.nj.us/ELEC_AGAA/EntitySearch.aspx

## Read

The results data was manually exported to the `data/raw/` directory.

```{r raw_dir}
raw_dir <- dir_create(here("il", "lobbying", "data", "raw"))
raw_info <- as_tibble(dir_info(raw_dir))
raw_info %>% 
  select(path, size, modification_time)
```

First, we will read the `LR_EXPENDITURES.csv` file containing the relationships
between lobbying agents, their firms, and the client entities they represent.

According to the [IL SOS](https://www.cyberdriveillinois.com/departments/index/lobbyist/lobbyist_search.html), 
> A lobbying entity is a corporation, association, group, firm or person that engages in activities that require registration under the Lobbyist Registration Act.
The entity's contact information will be displayed with exclusive lobbyist, contractual lobbyists and/or any clients the lobbying entity may represent. A contractual lobbyist is a person or firm that is retained to lobby on another firm's behalf. A client is any corporation, association, group, firm or person that retains a contractual lobbying entity to lobby on their behalf.
The lobbying entity registration search will also provide a list of state agencies a lobbying entity intends to lobby and the subject matter of their lobbying activities.
The Exclusive Lobbyist Registration Search allows you to view an exclusive lobbyist's contact information. An exclusive lobbyist is an employee of a registered lobbying entity. This search will list the lobbying entity for which the Lobbyist is employed, as well as display his or her photo.

More information about the registering entities and agents can be found in the [Illinois Lobbyists Registration Annual Registration Guide](https://www.cyberdriveillinois.com/publications/pdf_publications/ipub31.pdf).
> Companies that have individual employees whose duties include lobbying, or that have retained outside lobbyists
or lobbying entities to lobby on their behalf, are required to register as a lobbying entity. Each calendar year,
lobbying entities and exclusive lobbyists must register before any services are performed, no later than two
business days after being employed or retained.

>A Sub-Client is an external entity, who is one of your listed clients, for whom you anticipate lobbying. A registering
entity should not list themselves as their own sub-client. 

The exclusive lobbyist corresponds to in-house lobbyists in other states, while the contractual lobbyists likely work for lobbying firms contracted by entities. 

```{r raw_read}
utf_convert <- function(path, out) {
  system(glue("iconv -f UTF-16LE -t UTF-8 {path} -o {out}"))
}
tmp <- file_temp(ext = "csv")
utf_convert(path(raw_dir,"LR_EXPENDITURES.csv"), tmp)

x <- str_squish(read_lines(tmp))
sum(is.na(x)) # before
for (i in rev(seq_along(x)[-1])) { # go from back
  if (str_starts(x[i], "\\d+,\\d{4},\\d+")) {
    next() # skip if good
  } else { # collapse if bad
    x[i - 1] <- str_c(x[i - 1], x[i])
    x[i] <- NA_character_
  }
}
sum(is.na(x)) # after
write_lines(na.omit(x), tmp)

ille <- vroom(
  file = tmp,
  delim = ",",
  escape_backslash = FALSE,
  escape_double = TRUE,
  num_threads = 1,
  .name_repair = make_clean_names,
  col_types = cols(
    .default = col_character(),
    YEAR = col_integer(),
    REPORT_PERIOD = col_double(),
    EXPENDITURE_DATE = col_date("%Y%m%d"),
    EXPENDITURE_AMOUNT = col_double(),
    DATE_CREATED = col_datetime("%Y-%m-%d-%H.%M.%S"),
    DATE_UPDATED = col_datetime("%Y-%m-%d-%H.%M.%S")
  )
)
```


## Explore

```{r glimpse}
glimpse(ille)
tail(ille)
```

### Missing
```{r na_count}
col_stats(ille, count_na)
```
We will use the `campfin::flag_na()` function to flag records missing the `lobbyist_id` field. 
```{r}
ille <- ille %>% flag_na(lobbyist_id)
```

### Duplicates

We will flag entries that are identical. They may be duplicates.

```{r dupe_flag, warning=TRUE}
ille <- flag_dupes(ille, everything())
sum(ille$dupe_flag)
```

### Categorical

```{r distinct_count}
col_stats(ille, n_distinct)
```

### Dates
Most of the dates were read as strings. We'll need to manually convert them to date types.
```{r date conv}
ille <- ille %>%
  mutate(expenditure_date_clean = as.Date(expenditure_date, format = "%Y%m%d")) %>% 
  mutate_at(.vars = vars(starts_with("date")),.funs = as_datetime)
```

```{r date_range}
min(ille$expenditure_date_clean)
max(ille$expenditure_date_clean)
sum(ille$expenditure_date_clean > today())
```

```{r bar_year, echo=FALSE}
ille %>% 
  count(year) %>% 
  mutate(even = is_even(year)) %>% 
  ggplot(aes(x = year, y = n)) +
  geom_col(fill = dark2["purple"]) + 
  scale_fill_brewer(palette = "Dark2") +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(breaks = seq(1980, 2020, by = 2)) +
  coord_cartesian(xlim = c(1989, 2020)) +
  theme(legend.position = "bottom") +
  labs(
    title = "Illinois Lobbying Expenditures by Year",
    caption = "Source: IL SOS",
    x = "Year Made",
    y = "Count"
  )
```

```{r}
ille %>% 
filter(amount >= 1, amount < 1e5) %>% 
  ggplot(aes(x = reorder(party, amount), y = amount)) + 
  geom_violin(aes(fill = party)) + 
  scale_y_continuous(
    breaks = c(1 %o% 10^(0:5)),
    labels = dollar,
    trans = "log10"
  ) +
  scale_fill_manual(
    guide = FALSE,
    values = c(
      "brown", 
      "royalblue", 
      "forestgreen", 
      "gold",
      "mediumpurple", 
      "#999999", 
      "firebrick",
      "black"
    )
  ) +
  labs(
    title = "Washington State Campaign Expenditures",
    caption = "Source: data.wa.gov/d/tijg-9zyp",
    y = "Amount",
    x = "Party"
  )
```


## Join

Since this relational table only contains lobbyists' and entities' IDs, we will need to manually join such fields from `LR_LOBBYIST.csv` and `il_lob_reg.csv`. 

First, we will join the `lobbyist_id` from `LR_LOBBYIST.csv`. 
```{r join lob id}
illr_lob <- as_tibble(read.csv(file = path(raw_dir, "LR_LOBBYIST.csv"), stringsAsFactors = FALSE, fileEncoding = 'UTF-16LE')) %>% clean_names()
reg_dir <- here("il", "lobbying", "data", "clean","reg")
illr <- read_csv(file = dir_ls(reg_dir))
```
We will also need to match the year field. 
```{r}
illr_lob <- illr_lob %>% select(lobbyist_id, lobbyist_lname, lobbyist_fname, ent_reg_year)

ille <-  ille %>% mutate(year= as.numeric(year)) %>% 
left_join(illr_lob, by = c("year" = "ent_reg_year", "lobbyist_id"))

illr_join <- illr %>% select(ent_id, ent_reg_year, ent_name, ent_address_clean, ent_city_clean, ent_st_abbr_clean, ent_zip_clean)

ille <- ille %>% mutate(entity_id = as.numeric(entity_id)) %>% 
  left_join(illr_join, by = c("year" = "ent_reg_year", "entity_id"="ent_id"))
```




### Wrangle

To improve the searchability of the database, we will perform some consistent,
confident string normalization. For geographic variables like city names and
ZIP codes, the corresponding `campfin::normal_*()` functions are tailor made to 
facilitate this process.

### Address

For the street `addresss` variable, the `campfin::normal_address()` function
will force consistence case, remove punctuation, and abbreviate official 
USPS suffixes.

```{r address_norm}
ille <- ille %>% 
      # combine street addr
  unite(
    col = ent_address,
    starts_with("ent_addr"),
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
    unite(
    col = agent_address,
    starts_with("agent_addr"),
    sep = " ",
    remove = FALSE,
    na.rm = TRUE
  )

ille <- ille %>% mutate_at(
   .vars = vars(ends_with('address')), 
   .funs = list(norm = ~ normal_address(
    .,
     abbs = usps_street,
     na = invalid_city
   )
 ))
```

```{r address_view}
ille %>% 
  select(ends_with("address"), ends_with("address_norm")) %>% 
  distinct() %>% 
  sample_n(10)
ille <- ille %>% select(-ends_with("address"))
```

### ZIP

For ZIP codes, the `campfin::normal_zip()` function will attempt to create
valid _five_ digit codes by removing the ZIP+4 suffix and returning leading
zeroes dropped by other programs like Microsoft Excel.

```{r zip_norm}
ille <- ille %>% mutate_at(
  .vars = vars(ends_with("zip")),
  .funs = list(norm = ~ normal_zip(
    .,
    na_rep = TRUE
  )
)
)
```

```{r zip_progress}
progress_table(
  ille$ent_zip,
  ille$ent_zip_norm,
  ille$agent_zip,
  ille$agent_zip_norm,
  compare = valid_zip
)
```

### State

Valid two digit state abbreviations can be made using the 
`campfin::normal_state()` function.

```{r state_norm}
ille <- ille %>% 
  mutate_at(
    .vars = vars(ends_with("st_abbr")),
  .funs = list(norm = ~ normal_state(
      .,
      abbreviate = TRUE,
      na_rep = TRUE,
      valid = valid_state
    )
  )
  )
```

```{r state_progress}
progress_table(
  ille$ent_st_abbr,
  ille$ent_st_abbr_norm,
  ille$agent_st_abbr,
  ille$agent_st_abbr_norm,
  compare = valid_state
)
```

### City

Cities are the most difficult geographic variable to normalize, simply due to
the wide variety of valid cities and formats.

#### Normal

The `campfin::normal_city()` function is a good start, again converting case,
removing punctuation, but _expanding_ USPS abbreviations. We can also remove
`invalid_city` values.

```{r city_norm}
ille <- ille %>% 
  mutate_at(
    .vars = vars(ends_with("city")),
  .funs = list(norm = ~ normal_city(
      ., 
      abbs = usps_city,
      states = valid_state,
      na = invalid_city,
      na_rep = TRUE
    )
  )
  )
```

#### Swap

We can further improve normalization by comparing our normalized value
against the _expected_ value for that record's state abbreviation and ZIP code.
If the normalized value is either an abbreviation for or very similar to the
expected value, we can confidently swap those two.

```{r city_swap lobbyist}
ille <- ille %>% 
  left_join(
    y = zipcodes,
    by = c(
      "ent_st_abbr_norm" = "state",
      "ent_zip_norm" = "zip"
    )
  ) %>% 
  rename(ent_city_match = city) %>% 
  mutate(
    match_abb = is_abbrev(ent_city_norm, ent_city_match),
    match_dist = str_dist(ent_city_norm, ent_city_match),
    ent_city_swap = if_else(
      condition = !is.na(match_dist) & match_abb | match_dist == 1,
      true = ent_city_match,
      false = ent_city_norm
    )
  ) %>% 
  select(
    -ent_city_match,
    -match_dist,
    -match_abb
  )
```


#### Progress

```{r city_progress, echo=FALSE}
many_city <- c(valid_city, extra_city)
progress <- progress_table(
  str_to_upper(ille$ent_city),
  ille$ent_city_norm,
  ille$ent_city_swap,
    str_to_upper(ille$agent_city),
  ille$agent_city_norm,
  compare = many_city
) %>% mutate(stage = as_factor(stage))
kable(progress, digits = 3)
```

```{r}
ille <- ille %>% 
  select(-ent_city_norm) %>% 
  rename(ent_city_norm = ent_city_swap)
```

## Conclude

Before exporting, we can remove the intermediary normalization columns and
rename all added variables with the `_clean` suffix.

```{r clean_select}
ille <- ille %>% 
  rename_all(~str_replace(., "_norm", "_clean")) 
```

```{r clean_glimpse}
glimpse(sample_n(ille, 20))
```

1. There are `r comma(nrow(ille))` records in the database.
1. There are no duplicate records in the database.
1. The range and distribution of `amount` and `date` seem reasonable.
1. There are `r comma(sum(ille$na_flag))` records missing key variables.
1. Consistency in geographic data has been improved with `campfin::normal_*()`.
1. The 4-digit `year` variable has been created with `lubridate::year()`.

## Export

Now the file can be saved on disk for upload to the Accountability server.

```{r clean_dir}
clean_dir <- dir_create(here("il", "lobbying", "data", "clean","reg"))
clean_path <- path(clean_dir, "il_lobby_reg_clean.csv")
write_csv(ille, clean_path, na = "")
file_size(clean_path)
```

## Upload

Using the [duckr] R package, we can wrap around the [duck] command line tool to
upload the file to the IRW server.

[duckr]: https://github.com/kiernann/duckr
[duck]: https://duck.sh/

```{r clean_upload, eval=FALSE}
# remotes::install_github("kiernann/duckr")
s3_dir <- "s3:/publicaccountability/csv/"
s3_path <- path(s3_dir, basename(clean_path))
if (require(duckr)) {
  duckr::duck_upload(clean_path, s3_path)
}
```
