---
title: "District Contributions"
author: "Kiernan Nicholls"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  dcrning = FALSE,
  message = FALSE,
  error = FALSE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

```{r p_load, message=FALSE, dcrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  stringdist, # levenshtein value
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe opperators
  jsonlite, # reading JSON
  janitor, # dataframe clean
  zipcode, # clean & database
  refinr, # cluster & merge
  vroom, # quickly read files
  knitr, # knit documents
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

```{r fix_fun, echo=FALSE}
# fix conflict
here <- here::here
# custom utility functions
"%out%" <- Negate("%in%")
print_all <- function(dc) dc %>% print(n = nrow(.)) 
# source functions
source(here("R", "code", "normalize_geo.R"))
source(here("R", "code", "all_files_new.R"))
source(here("R", "code", "glimpse_fun.R"))
# load data
geo <- read_csv(here("R", "data", "geo.csv"))
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here, collapse=TRUE}
# where dcs this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

Data comes courtesy of the Washington, [DC Office of Campaign Finance (OCF)][03].

The data was published 2016-10-06 and was last updated 2019-05-07. Each record represents a single
contribution made.

As the [OCF website][04] explains: 

> The Office of Campaign Finance (OCF) provides easy access to all contributions and expenditures reported from 2003, through the current reporting period. Because the system is updated on a daily basis, you may be able to retrieve data received by OCF after the latest reporting period. This data is as reported, but may not be complete.

[03]: https://ocf.dc.gov/ "OCF"
[04]: https://ocf.dc.gov/service/view-contributions-expenditures

### About

The data is found on the dc.gov [OpenData website][05]. The file abstract reads:

> The Office of Campaign Finance (OCF) is pleased to publicly share election campaign contribution
data. The Campaign Finance Office is charged with administering and enforcing the District of
Columbia laws pertaining to campaign finance operations, lobbying activities, conflict of interest
matters, the ethical conduct of public officials, and constituent service and statehood fund
programs. OCF provides easy access to all contributions and expenditures reported from 2003,
through the current reporting period. Because the system is updated on a daily basis, you may be
able to retrieve data received by OCF after the latest reporting period. This data is as reported,
but may not be complete. Visit the http://ocf.dc.gov for more information.
> 
> Users may also visit the [Candidate Campaign][06] Contributions web application to find financial
data by zip codes.

[05]: https://opendata.dc.gov/datasets/campaign-financial-contributions
[06]: http://geospatial.dcgis.dc.gov/ocf/

> Keywords:
> * contributions
> * dc
> * dc gis
> * elections
> * expenditures
> * finance
> * money
> * oct2016
> * political
> * public service
> * vote
> * washington dc

> Contact:
> * Organization: D.C. Office of the Chief Technology Officer
> * Person: GIS Data Coordinator
> * Address: Address: 200 I Street SE, 5th Floor, Washington DC 20003 USA
> * Facsimile Telephone: (202) 727-5660
> * Electronic Mail Address: dcgis@dc.gov
> * Hours: 8:30 am - 5 pm

## Import

We can retreive the data from the GeoJSON API using the `jsonlite::fromJSON()` function.

```{r download_json}
dir_raw <- here("dc", "contribs", "data", "raw")
dir_create(dir_raw)

dc <- 
  fromJSON("https://opendata.arcgis.com/datasets/6443e0b5b2454e86a3208b8a38fdee84_34.geojson") %>% 
  use_series(features) %>% 
  use_series(properties) %>% 
  as_tibble() %>% 
  clean_names() %>%
  mutate_if(is_character, str_to_upper) %>% 
  mutate_at(vars(dateofreceipt), parse_datetime) %>% 
  select(
    -xcoord, 
    -ycoord, 
    -fulladdress, 
    -gis_last_mod_dttm,
  )
```

Then save a copy of the data frame to the disk in the `/data/raw` directory.

```{r write_raw}
write_delim(
  x = dc,
  path = glue("{dir_raw}/Campaign_Financial_Contributions.csv"),
  delim = ";",
  na = "",
  append = FALSE,
  col_names = TRUE,
  quote_escape = "double"
)
```

```{r download_raw, echo=FALSE, eval=FALSE}
dir_raw <- here("dc", "contribs", "data", "raw")
dir_create(dir_raw)

download.file(
  url = "https://opendata.arcgis.com/datasets/6443e0b5b2454e86a3208b8a38fdee84_34.csv",
  destfile = glue("{dir_raw}/Campaign_Financial_Contributions.csv")
)
```

## Explore

There are `r nrow(dc)` records of `r length(dc)` variables in the full database.

```{r glimpse}
head(dc)
tail(dc)
glimpse(dc)
```

### Distinct

The variables range in their degree of distinctness.

```{r n_distinct}
dc %>% glimpse_fun(n_distinct)
```

```{r who_bar, echo=FALSE}
dc %>% 
  mutate(
    contributortype = if_else(
      condition = contributortype %in% c("INDIVIDUAL", "CORPORATION"),
      true = contributortype,
      false = "ALL OTHER"
    )
  ) %>% 
  ggplot() +
  geom_bar(aes(contributortype))
```

```{r how_bar, echo=FALSE}
dc %>% 
  mutate(
    contributiontype = if_else(
      condition = contributiontype %in% c("CHECK", "CREDIT CARD", "CASH"),
      true = contributiontype,
      false = "ALL OTHER"
    )
  ) %>%
  ggplot() +
  geom_bar(aes(contributiontype))
```

```{r ward_bar, echo=FALSE}
dc %>% 
  ggplot() +
  geom_bar(aes(ward))
```

### Map

```{r size_point_map}
get_map(
  location = "Washington, DC", 
  zoom = 12, 
  maptype = "roadmap"
) %>% 
  ggmap() +
  geom_point(
    data = dc %>% filter(amount %>% between(0, 1000)),
    alpha = 0.01,
    mapping = aes(x = longitude, y = latitude, size = amount)
  )
```

### Missing

There are several variables missing key values:

```{r count_na}
dc %>% glimpse_fun(count_na)
```

Any row with a missing `contributorname` _or_ `amount` value will have a `TRUE` value in the new
`na_flag` variable.

```{r na_flag}
dc <- dc %>% mutate(na_flag = is.na(contributorname) | is.na(amount))
```

### Duplicates

There are no duplicate records.

```{r get_dupes, collapse=TRUE}
dc_dupes <- get_dupes(dc)
nrow(dc_dupes)
```

### Ranges

#### Amounts

The `amount` varies from `r scales::dollar(min(dc$amount, na.rm = T))` to 
`r scales::dollar(max(dc$amount, na.rm = T))`.

```{r amount_range, collapse=TRUE}
summary(dc$amount)
sum(dc$amount < 0, na.rm = TRUE)
```

```{r amount_hist, echo=FALSE}
dc %>% 
  ggplot() +
  geom_histogram(aes(amount)) +
  scale_x_continuous(
    labels = scales::dollar, 
    trans = "log10"
  )
```

```{r amount_hist_how, echo=FALSE}
dc %>%
  filter(contributortype %in% c("INDIVIDUAL", "CORPORATION")) %>% 
  ggplot() +
  geom_histogram(aes(amount)) +
  facet_wrap(~contributortype, ncol = 1) +
  scale_x_continuous(
    labels = scales::dollar, 
    trans = "log10"
  )
```

```{r amount_box_who, echo=FALSE}
dc %>%
  filter(contributortype %in% c("INDIVIDUAL", "CORPORATION")) %>% 
  ggplot() +
  geom_boxplot(
    mapping = aes(contributortype, amount),
    varwidth = TRUE,
    outlier.alpha = 0.10
  ) +
  scale_y_continuous(
    labels = scales::dollar, 
    trans = "log10"
  )
```

```{r amount_box_how}
dc %>% 
  filter(contributiontype %in% c("CHECK", "CREDIT CARD", "CASH", "OTHER")) %>% 
  ggplot() +
  geom_boxplot(
    mapping = aes(contributiontype, amount),
    varwidth = TRUE,
    outlier.alpha = 0.10
  ) +
  scale_y_continuous(
    labels = scales::dollar, 
    trans = "log10"
  )
```

### Dates

The dates range from `r min(dc$dc$dateofreceipt)` and `r max(dc$dc$dateofreceipt)`. There are
`r sum(dc$dateofreceipt > today())` records with a date greater than `r today()`.

```{r date_range, collapse=TRUE}
summary(dc$dateofreceipt)
sum(dc$dateofreceipt > today())
```

```{r year_bar, echo=FALSE}
dc %>% 
  ggplot() +
  geom_bar(aes(electionyear)) +
  scale_x_continuous(labels = 2002:2020, breaks = 2002:2020)
```

```{r amount_line_month, echo=FALSE}
dc %>%
  filter(!is.na(electionyear)) %>% 
  mutate(on_year = electionyear %% 2 == 0) %>% 
  group_by(on_year, month = month(dateofreceipt)) %>% 
  summarise(median = mean(amount, na.rm = TRUE)) %>% 
  ggplot(aes(x = month, y = median)) +
  geom_line(aes(color = on_year), size = 2) +
  scale_x_continuous(labels = month.abb, breaks = 1:12)
```

## Wrangle

We will have to break the `address` variable into `address`, `city`, `state`, and `zip`.

```{r head_address}
head(dc$address)
```

First, we will extract the ZIP digits from the end of the `address` string.

```{r norm_zip}
dc <- dc %>% 
  mutate(
    zip_clean = address %>% 
      str_extract("\\d{5}(?:-\\d{4})?$") %>% 
      normalize_zip(na_rep = TRUE)
  )
```

Then we can get the two digit state abbreviation preceding those digits.

```{r norm_state}
dc <- dc %>% 
  mutate(
    state_clean = address %>% 
      str_extract(",\\s[:alpha:]+(?=[:space:]+[:digit:]{5}(?:-[:digit:]{4})?$)") %>% 
      normalize_state(
        na = c("UNKNOWN", "TBD", "INFORMATION", "REQUESTED"), 
        expand = TRUE
      )
  )

n_distinct(dc$state_clean)
```

```{r}

```


