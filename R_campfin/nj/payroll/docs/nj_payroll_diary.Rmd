---
title: "New Jersey Payroll Data Diary"
author: "Yanqi Xu"
date: "`r format(Sys.time())`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
fs::dir_create(here::here("nj", "payroll", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  pdftools, # wrangle PDFs
  readxl, # read excel files
  tidyverse, # data manipulation
  lubridate, # datetime strings
  gluedown, # printing markdown
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here}
# where does this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Registration

Data is obtained from the [State of New Jersey's data portal][data portal]. According to the website, the data was created Created July 11, 2014 and Last Updated on February, 2020. It comes from NJ Office of Management and Budget.

> This dataset contains data for State employees paid through the Centralized Payroll System. The data reflects payroll payments made to the employee for the calendar year through the date indicated. There are two types of records: MASTER and DETAIL. There is at least one MASTER and one DETAIL record per employee. Multiple DETAIL records for an employee will appear in the file for a specific year if the employee is paid by more than one department/agency or by more than one section during that calendar year. The sums for all of the departments/agencies appear in the columns with prefix “MASTER”. Additional information is in the attached dataset summary PDF (available on the [About] tab under "Attachments").

[data portal]: https://data.ny.gov/City-Government/Citywide-Payroll-Data-Fiscal-Year-/k397-673e

```{r raw_dir}
# raw_dir stores the raw data file
raw_dir <- dir_create(here("nj", "payroll", "data", "raw"))
# data dir is a level up from raw_dir, I used it to store dictionary and temp files like fixed.txt
data_dir <- here("nj", "payroll", "data")
```

### Import
Besides the raw data, the portal also makes [column specifications available for download in PDF](https://data.nj.gov/api/views/iqwc-r2w7/files/zr33DGJd7cSZPfDBXdG_aW0npV_6Bl7w-3_HQxiDx1I?download=true&filename=AgencyPayrollDatasetSummary.pdf).

```{r scrape web dict, eval=FALSE}
dict_url <- 'https://data.nj.gov/api/views/iqwc-r2w7/files/zr33DGJd7cSZPfDBXdG_aW0npV_6Bl7w-3_HQxiDx1I?download=true&filename=AgencyPayrollDatasetSummary.pdf'
# extract the name of the dictionary file
dict_fs <- str_extract(dict_url, "(?<=filename=).*")
# download dictionary file to data_dir
nj_dict <- download.file(dict_url, destfile = path(data_dir, dict_fs))
```

```{r read dict}
dict_pdf <- dir_ls(data_dir, glob = "*.pdf")

dict_lines <- pdf_text(dict_pdf) %>% read_lines()
# find the index of rows where "Column Name" show up
start_index <- which(str_detect(dict_lines, "Column Name"))
#21 45 93
# extra lines to get rid of, 4 lines at a time
to_elim <- c(start_index-3, start_index-2, start_index-1,start_index)
dict_lines <- dict_lines[-to_elim]
# get rid of all lines before the first valid line, here it's supposed to be start_index [1] + 1, but remember we removed 4 lines
dict_lines <- dict_lines[(start_index[1]-3):(length(dict_lines)-1)]
# Separate the lines into a dataframe of two columns
dict <- dict_lines %>% read_fwf(fwf_widths(c(29,100), 
                                           c("Column Name", "Column Description")
                                           )
                                )
# This syntax works for all dataframes with rows spanning multiple columns, it's basically a group_by and summarize function with lambda 
dict <- dict %>% group_by(`Column Name`) %>% summarise_all(list(~ paste(., collapse = " ")))
```

```{r dict kable, echo=FALSE}
# this line of code generates a knitted html table from the Markdown syntax.
kable(dict)
```

We can set column specifications according to the record layout as such.
```{r raw_read}
njp <- dir_ls(raw_dir) %>% read_csv()
njp <- njp %>% 
  # replace "null" records with NAs
   na_if("null") %>% 
  mutate(
    # the format of date and time in R can be found here https://statistics.berkeley.edu/computing/r-dates-times
    AS_OF_DATE = as.Date(AS_OF_DATE, format = "%b %d %Y"),
    # December 31 2019 is spelled out full month[space]date[space]four-digit year
    # ORIGINAL_EMPLOYMENT_DTE's format is different, e.g. 2/6/2006
    ORIGINAL_EMPLOYMENT_DTE = as.Date(ORIGINAL_EMPLOYMENT_DTE, format = "%m/%d/%Y")) %>% 
  mutate_at(.vars = c(
    SALARY_HOURLY_RATE, 
    REGULAR_PAY,
    SUPPLEMENTAL_PAY,
    ONE_TIME_PAYMENTS,
    LEGISLATOR_OR_BACK_PAY,
    OVERTIME_PAYMENTS,
    CLOTHING_UNIFORM_PAYMENTS,
    RETROACTIVE_PAY,
    LUMP_SUM_PAY,
    YTD_EARNINGS,
    CASH_IN_LIEU_MAINTENANCE),
    .funs = as.numeric
  )
```

### Explore

```{r raw_glimpse}
head(njp)
tail(njp)
glimpse(sample_frac(njp))
```


Then we can take a look at the _NA_ fields and number of distinct values for each column. 
```{r n_distinct}
col_stats(njp, count_na)
col_stats(njp, n_distinct) 
```
We'll use the `campfin:flag_dupe()` function to flag the records without any names and title description
```{r flag na}
njp <- njp %>% 
  flag_na(first_name, last_name, title_description)
```


```{r count_na}
col_stats(njp, count_na)
```

There are no duplicate rows in the database.

```{r duplicated}
njp <- flag_dupes(njp, dplyr::everything())
sum(njp$dupe_flag)
```


```{r year_plot, echo=FALSE}
njp %>% 
  count(calendar_year) %>% 
  ggplot(aes(x = calendar_year, y = n)) +
  geom_col(fill = RColorBrewer::brewer.pal(3, "Dark2")[3]) +
  labs(
    title = "New Jersey Staff Payroll Head Counts per Year",
    x = "Fiscal Year",
    y = "Staffers"
  )
```


## Wrangle

### State

We can add the state column.

```{r add state}
njp <- njp %>% 
  mutate(state = "NJ")
```

## Conclude

```{r clean_glimpse}
glimpse(sample_n(njp, 20))
```

1. There are `r nrow(njp)` records in the database.
1. There are `r sum(njp$dupe_flag)` duplicate records in the database.
1. The range and distribution of `year` seems mostly reasonable except for a few entries.
1. There are `r sum(njp$na_flag)` records missing either recipient or date.
1. Consistency in goegraphic data has been improved with `campfin::normal_*()`.

We can plot the distribution of total compensations by different departments.
```{r dept violin, include=FALSE, eval=FALSE}
njp %>% 
  ggplot(aes(x = reorder(agency_name, total_gross_pay), y = total_gross_pay)) + 
  geom_violin(aes(fill = agency_name)) + 
  scale_y_continuous(
    breaks = c(1 %o% 10^(0:5)),
    labels = dollar,
    trans = "log10"
  ) +
  scale_fill_manual(
    guide = FALSE,
    values = c(
      "brown", 
      "royalblue", 
      "forestgreen", 
      "gold",
      "mediumpurple", 
      "#999999", 
      "firebrick",
      "black"
    )
  ) +
  labs(
    title = "New Jersey State Salary Distribution",
    caption = "Source: ",
    y = "Amount",
    x = "Department"
  )
```

### Export

```{r proc_dir}
proc_dir <- dir_create(here("nj", "payroll", "data", "processed"))
```

```{r proc_write}
write_csv(
  x = njp,
  path = path(proc_dir, "ny_payroll_clean.csv"),
  na = ""
)
```
