---
title: "State Data"
author: "First Last"
date: "`r Sys.time()`"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

<!-- Place comments regarding knitting here -->

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = FALSE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(5)
```

```{r create_docs_dir, eval=FALSE, echo=FALSE, include=FALSE}
fs::dir_create(here::here("df", "data", "docs"))
```

## Project

The Accountability Project is an effort to cut across data silos and give journalists, policy
professionals, activists, and the public at large a simple way to search across huge volumes of
public data about people and organizations.

Our goal is to standardizing public data on a few key fields by thinking of each dataset row as a
transaction. For each transaction there should be (at least) 3 variables:

1. All **parties** to a transaction
2. The **date** of the transaction
3. The **amount** of money involved

## Objectives

This document describes the process used to complete the following objectives:

1. How many records are in the database?
1. Check for duplicates
1. Check ranges
1. Is there anything blank or missing?
1. Check for consistency issues
1. Create a five-digit ZIP Code called `ZIP5`
1. Create a `YEAR` field from the transaction date
1. Make sure there is data on both parties to a transaction

## Packages

The following packages are needed to collect, manipulate, visualize, analyze, and communicate
these results. The `pacman` package will facilitate their installation and attachment.

The IRW's `campfin` package will also have to be installed from GitHub. This package contains
functions custom made to help facilitate the processing of campaign finance data.

```{r load_packages, message=FALSE, dfrning=FALSE, error=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("irworkshop/campfin")
pacman::p_load(
  stringdist, # levenshtein value
  RSelenium, # remote browser
  tidyverse, # data manipulation
  lubridate, # datetime strings
  magrittr, # pipe opperators
  janitor, # dataframe clean
  refinr, # cluster and merge
  scales, # format strings
  knitr, # knit documents
  vroom, # read files fast
  glue, # combine strings
  here, # relative storage
  fs # search storage 
)
```

This document should be run as part of the `R_campfin` project, which lives as a sub-directory of
the more general, language-agnostic [`irworkshop/accountability_datacleaning`][01] GitHub
repository.

The `R_campfin` project uses the [RStudio projects][02] feature and should be run as such. The
project also uses the dynamic `here::here()` tool for file paths relative to _your_ machine.

```{r where_here, collapse=TRUE}
# where does this document knit?
here::here()
```

[01]: https://github.com/irworkshop/accountability_datacleaning "TAP repo"
[02]: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "Rproj"

## Data

### About

### Variables

## Import

### Download

```{r download_raw}

```

### Read

```{r read_raw}

```

## Explore

```{r glimpse}
head(df)
tail(df)
glimpse(sample_frac(df))
```

### Missing

```{r glimpse_na}
glimpse_fun(df, count_na)
```

```{r flag_na}
df <- df %>% flag_na(payee, filer, date, amount)
```

### Duplicates

```{r flag_dupes}
df <- flag_dupes(df, -id)
```

### Categorical

```{r glimpse_distinct}
glimpse_fun(df, n_distinct)
```

### Continuous

#### Amounts

```{r summary_amount}
summary(df$amount)
```

```{r amount_histogram, echo=FALSE}
df %>%
  ggplot(aes(amount)) +
  geom_histogram() +
  scale_x_continuous(
    breaks = c(1 %o% 10^(0:6)),
    labels = dollar,
    trans = "log10"
  ) +
  labs(
    title = "State Data Amount Distribution",
    subtitle = "from 2000 to 2019",
    caption = "Source: State Agency Name",
    x = "Amount",
    y = "Count"
  )
```

#### Dates

```{r}
df <- mutate(df, year = year(date))
```

```{r date_range, collapse=TRUE}
min(df$date)
sum(df$year < 2000)
max(df$date)
sum(df$date > today())
```

## Wrangle

### Address

```{r normal_address}
packageVersion("tidyr")
df <- df %>% 
  # combine street addr
  unite(
    col = adress_full,
    starts_with("address"),
    remove = FALSE,
    na.rm = TRUE
  ) %>% 
  # normalize combined addr
  mutate(
    address_norm = normal_address(
      address = adress_full,
      add_abbs = usps,
      na_rep = TRUE
    )
  )
```

### ZIP

```{r count_zip_pre, collapse=TRUE}
n_distinct(df$zip)
prop_in(df$zip, valid_zip, na.rm = TRUE)
length(setdiff(df$zip, valid_zip))
```

```{r normal_zip}
df <- df %>% 
  mutate(
    zip_norm = normal_zip(
      zip = zip,
      na_rep = TRUE
    )
  )
```

```{r count_zip_post, collapse=TRUE}
n_distinct(df$zip_norm)
prop_in(df$zip_norm, valid_zip, na.rm = TRUE)
length(setdiff(df$zip_norm, valid_zip))
```

### State

```{r count_state_pre, collapse=TRUE}
n_distinct(df$state)
prop_in(df$state, valid_state, na.rm = TRUE)
length(setdiff(df$state, valid_state))
```

```{r normal_state}
df <- df %>% 
  mutate(
    state_norm = normal_state(
      state = state,
      abbreviate = TRUE,
      na_rep = TRUE,
      valid = valid_state
    )
  )
```

```{r count_state_post, collapse=TRUE}
n_distinct(df$state_norm)
prop_in(df$state_norm, valid_state, na.rm = TRUE)
length(setdiff(df$state_norm, valid_state))
```

### City

```{r count_city_pre, collapse=TRUE}
n_distinct(df$city)
prop_in(df$city, valid_city, na.rm = TRUE)
length(setdiff(df$city, valid_city))
```

#### Normalize

```{r normal_city}
df <- df %>% 
  mutate(
    city_norm = normal_city(
      city = city, 
      geo_abbs = usps_city,
      st_abbs = c("DF", "DC", "DATA FRAME"),
      na = invalid_city,
      na_rep = TRUE
    )
  )
```

```{r count_city_post_norm, collapse=TRUE}
n_distinct(df$city_norm)
prop_in(df$city_norm, valid_city, na.rm = TRUE)
length(setdiff(df$city_norm, valid_city))
```

#### Swap

```{r swap_city}
df <- df %>% 
  left_join(
    y = zipcodes,
    by = c(
      "state_norm" = "state",
      "zip_norm" = "zip"
    )
  ) %>% 
  rename(city_match = city) %>% 
  mutate(
    match_dist = stringdist(city_norm, city_match),
    city_swap = if_else(
      condition = equals(match_dist, 1),
      true = city_match,
      false = city_norm
    )
  )
```

```{r count_city_post_swap, collapse=TRUE}
n_distinct(df$city_swap)
prop_in(df$city_swap, valid_city, na.rm = TRUE)
length(setdiff(df$city_swap, valid_city))
```

#### Refine

## Conclude

1. There are `nrow(df)` records in the database.
1. There are `sum(df$dupe_flag)` duplicate records in the database.
1. The range and distribution of `amount` and `date` seem reasonable.
1. There are `sum(df$na_flag)` records missing either recipient or date.
1. Consistency in goegraphic data has been improved with `campfin::normal_*()`.
1. The 5-digit `zip_norm` variable has been created with `campfin::normal_zip(df$zip)`.
1. The 4-digit `year` variable has been created with `lubridate::year()`.

## Export
